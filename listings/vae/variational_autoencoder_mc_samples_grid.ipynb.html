<!DOCTYPE html>
<html prefix="
og: http://ogp.me/ns#
article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="variational_autoencoder_mc_samples_grid.ipynb">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>variational_autoencoder_mc_samples_grid.ipynb | Louis Tiao</title>
<link href="../../assets/css/all.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/override_nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="http://louistiao.me/listings/vae/variational_autoencoder_mc_samples_grid.ipynb.html">
<link rel="icon" href="../../favicon_16x16.ico" sizes="16x16">
<link rel="icon" href="../../favicon_32x32.ico" sizes="32x32">
<link rel="icon" href="../../favicon_256x256.ico" sizes="256x256">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script><!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><!--

    /\\\\\\\\\\\\\\\  /\\\\\\\\\\\     /\\\\\\\\\          /\\\\\              
    \///////\\\/////  \/////\\\///    /\\\\\\\\\\\\\      /\\\///\\\           
           \/\\\           \/\\\      /\\\/////////\\\   /\\\/  \///\\\        
            \/\\\           \/\\\     \/\\\       \/\\\  /\\\      \//\\\      
             \/\\\           \/\\\     \/\\\\\\\\\\\\\\\ \/\\\       \/\\\     
              \/\\\           \/\\\     \/\\\/////////\\\ \//\\\      /\\\     
               \/\\\           \/\\\     \/\\\       \/\\\  \///\\\  /\\\      
                \/\\\        /\\\\\\\\\\\ \/\\\       \/\\\    \///\\\\\/      
                 \///        \///////////  \///        \///       \/////       

-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

  <div class="container">
    <div class="header clearfix">
      <nav><ul class="nav nav-pills pull-right">
<li>
<a href="../../">About</a>
                </li>
<li>
<a href="../../projects/">Projects</a>
                </li>
<li>
<a href="../../posts/">Posts</a>
                </li>
<li>
<a href="../../archive.html">Archive</a>

          
        </li>
</ul></nav><a href="http://louistiao.me/">

        <h3 class="text-muted">
          <span id="blog-title">Louis Tiao</span>
        </h3>
      </a>
    </div>

<!-- TODO Figure out what to do with this stuff -->
<!--     <div class="row">

      <ul class="nav nav-pills pull-right">
    <li>
    <a href="/listings/vae/variational_autoencoder_mc_samples_grid.ipynb" id="sourcelink">Source</a>
    </li>
          
      </ul>
    </div> -->

    <div id="content" role="main">
      <div class="body-content">
        <!--Body content-->
        <div class="row">
          
<nav class="breadcrumbs"><ul class="breadcrumb">
<li><a href="../">listings</a></li>
                <li><a href=".">vae</a></li>
                <li>variational_autoencoder_mc_samples_grid.ipynb</li>
</ul></nav><h1>variational_autoencoder_mc_samples_grid.ipynb
        <small><a href="variational_autoencoder_mc_samples_grid.ipynb">(Source)</a></small>
    </h1>
    <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Preamble">Preamble<a class="anchor-link" href="#Preamble">¶</a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> notebook
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="k">import</span> <span class="n">norm</span>

<span class="kn">from</span> <span class="nn">keras</span> <span class="k">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>

<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="p">(</span><span class="n">Input</span><span class="p">,</span> <span class="n">InputLayer</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">,</span> <span class="n">Layer</span><span class="p">,</span> 
                          <span class="n">Add</span><span class="p">,</span> <span class="n">Multiply</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="k">import</span> <span class="n">mnist</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="k">import</span> <span class="n">FormatStrFormatter</span>
<span class="kn">from</span> <span class="nn">keras.utils.vis_utils</span> <span class="k">import</span> <span class="n">model_to_dot</span><span class="p">,</span> <span class="n">plot_model</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="k">import</span> <span class="n">SVG</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Notebook-Configuration">Notebook Configuration<a class="anchor-link" href="#Notebook-Configuration">¶</a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">edgeitems</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                    <span class="n">linewidth</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span>
                    <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="s1">'TensorFlow version: '</span> <span class="o">+</span> <span class="n">K</span><span class="o">.</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt output_prompt">Out[5]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>'TensorFlow version: 1.4.0'</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="Constant-definitions">Constant definitions<a class="anchor-link" href="#Constant-definitions">¶</a>
</h5>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">batch_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span> 
<span class="n">mc_sample_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">25</span><span class="p">]</span>

<span class="n">original_dim</span> <span class="o">=</span> <span class="mi">784</span>
<span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">intermediate_dim</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">epsilon_std</span> <span class="o">=</span> <span class="mf">1.0</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">nll</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="sd">""" Bernoulli negative log likelihood. """</span>

    <span class="c1"># keras.losses.binary_crossentropy gives the mean</span>
    <span class="c1"># over the last axis. We require the sum.</span>
    <span class="k">return</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">binary_crossentropy</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">KLDivergenceLayer</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>

    <span class="sd">""" Identity transform layer that adds KL divergence</span>
<span class="sd">    to the final model loss.</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_placeholder</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">KLDivergenceLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>

        <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span> <span class="o">=</span> <span class="n">inputs</span>

        <span class="n">kl_batch</span> <span class="o">=</span> <span class="o">-</span> <span class="o">.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">log_var</span> <span class="o">-</span>
                                <span class="n">K</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span> <span class="o">-</span>
                                <span class="n">K</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_var</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">kl_batch</span><span class="p">),</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">inputs</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">build_vae</span><span class="p">(</span><span class="n">mc_sample_size</span><span class="p">,</span> <span class="n">original_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span> <span class="n">intermediate_dim</span><span class="p">):</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">original_dim</span><span class="p">,))</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">intermediate_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">z_mu</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">)(</span><span class="n">h</span><span class="p">)</span>
    <span class="n">z_log_var</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">)(</span><span class="n">h</span><span class="p">)</span>

    <span class="n">z_mu</span><span class="p">,</span> <span class="n">z_log_var</span> <span class="o">=</span> <span class="n">KLDivergenceLayer</span><span class="p">()([</span><span class="n">z_mu</span><span class="p">,</span> <span class="n">z_log_var</span><span class="p">])</span>
    <span class="n">z_sigma</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">K</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="n">t</span><span class="p">))(</span><span class="n">z_log_var</span><span class="p">)</span>

    <span class="n">eps</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">K</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span><span class="n">stddev</span><span class="o">=</span><span class="n">epsilon_std</span><span class="p">,</span>
                                       <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
                                              <span class="n">mc_sample_size</span><span class="p">,</span>
                                              <span class="n">latent_dim</span><span class="p">)))</span>

    <span class="n">z_eps</span> <span class="o">=</span> <span class="n">Multiply</span><span class="p">()([</span><span class="n">z_sigma</span><span class="p">,</span> <span class="n">eps</span><span class="p">])</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">Add</span><span class="p">()([</span><span class="n">z_mu</span><span class="p">,</span> <span class="n">z_eps</span><span class="p">])</span>

    <span class="n">decoder</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
        <span class="n">Dense</span><span class="p">(</span><span class="n">intermediate_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
        <span class="n">Dense</span><span class="p">(</span><span class="n">original_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">)</span>
    <span class="p">])</span>

    <span class="n">x_mean</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">eps</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="n">x_mean</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">original_dim</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">original_dim</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">histories</span> <span class="o">=</span> <span class="p">[]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">timeit</span>

for batch_size in batch_sizes:

    histories_batch_size = []
    
    for mc_sample_size in mc_sample_sizes:

        print('batch size {} | MC sample size {}'
              .format(batch_size, mc_sample_size))

        x_train_target = np.tile(np.expand_dims(x_train, axis=1),
                                 reps=(1, mc_sample_size, 1))
        x_test_target = np.tile(np.expand_dims(x_test, axis=1),
                                reps=(1, mc_sample_size, 1))

        vae = build_vae(mc_sample_size, original_dim, latent_dim, 
                        intermediate_dim)
        vae.compile(optimizer='rmsprop', loss=nll)

        histories_batch_size.append(
            vae.fit(x_train,
                    x_train_target,
                    shuffle=True,
                    epochs=epochs,
                    batch_size=batch_size,
                    validation_data=(x_test, x_test_target))
        )
    
    histories.append(histories_batch_size)
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>batch size 25 | MC sample size 1
Train on 60000 samples, validate on 10000 samples
Epoch 1/50
60000/60000 [==============================] - 8s 128us/step - loss: 175.1970 - val_loss: 166.8884
Epoch 2/50
60000/60000 [==============================] - 6s 108us/step - loss: 164.7072 - val_loss: 162.9183
Epoch 3/50
60000/60000 [==============================] - 7s 116us/step - loss: 161.5457 - val_loss: 160.4000
Epoch 4/50
60000/60000 [==============================] - 7s 113us/step - loss: 159.7933 - val_loss: 159.0190
Epoch 5/50
60000/60000 [==============================] - 7s 109us/step - loss: 158.6401 - val_loss: 158.6160
Epoch 6/50
60000/60000 [==============================] - 6s 108us/step - loss: 157.8559 - val_loss: 157.5280
Epoch 7/50
60000/60000 [==============================] - 6s 108us/step - loss: 157.1781 - val_loss: 156.8357
Epoch 8/50
60000/60000 [==============================] - 7s 109us/step - loss: 156.6294 - val_loss: 156.9744
Epoch 9/50
60000/60000 [==============================] - 7s 109us/step - loss: 156.1520 - val_loss: 156.3271
Epoch 10/50
60000/60000 [==============================] - 7s 113us/step - loss: 155.7995 - val_loss: 155.6093
Epoch 11/50
60000/60000 [==============================] - 7s 112us/step - loss: 155.4761 - val_loss: 155.8117
Epoch 12/50
60000/60000 [==============================] - 7s 113us/step - loss: 155.2142 - val_loss: 155.3306
Epoch 13/50
60000/60000 [==============================] - 7s 113us/step - loss: 154.9656 - val_loss: 155.0260
Epoch 14/50
60000/60000 [==============================] - 7s 114us/step - loss: 154.8004 - val_loss: 155.0653
Epoch 15/50
60000/60000 [==============================] - 7s 113us/step - loss: 154.5534 - val_loss: 155.1766
Epoch 16/50
60000/60000 [==============================] - 7s 119us/step - loss: 154.3994 - val_loss: 154.8735
Epoch 17/50
60000/60000 [==============================] - 9s 146us/step - loss: 154.2507 - val_loss: 154.5887
Epoch 18/50
60000/60000 [==============================] - 9s 148us/step - loss: 154.0771 - val_loss: 154.5812
Epoch 19/50
60000/60000 [==============================] - 7s 120us/step - loss: 153.9040 - val_loss: 154.7645
Epoch 20/50
60000/60000 [==============================] - 7s 116us/step - loss: 153.7820 - val_loss: 153.9356
Epoch 21/50
60000/60000 [==============================] - 7s 114us/step - loss: 153.6550 - val_loss: 153.9721
Epoch 22/50
60000/60000 [==============================] - 7s 115us/step - loss: 153.5831 - val_loss: 153.7020
Epoch 23/50
60000/60000 [==============================] - 7s 116us/step - loss: 153.4567 - val_loss: 153.6845
Epoch 24/50
60000/60000 [==============================] - 7s 114us/step - loss: 153.3308 - val_loss: 153.8533
Epoch 25/50
60000/60000 [==============================] - 7s 117us/step - loss: 153.3213 - val_loss: 153.9720
Epoch 26/50
60000/60000 [==============================] - 7s 114us/step - loss: 153.2821 - val_loss: 154.1556
Epoch 27/50
60000/60000 [==============================] - 7s 115us/step - loss: 153.2045 - val_loss: 154.0935
Epoch 28/50
60000/60000 [==============================] - 7s 115us/step - loss: 153.1441 - val_loss: 154.0715
Epoch 29/50
60000/60000 [==============================] - 7s 114us/step - loss: 153.0656 - val_loss: 154.3373
Epoch 30/50
60000/60000 [==============================] - 7s 116us/step - loss: 153.0043 - val_loss: 153.9538
Epoch 31/50
60000/60000 [==============================] - 7s 115us/step - loss: 152.9843 - val_loss: 153.5975
Epoch 32/50
60000/60000 [==============================] - 7s 115us/step - loss: 152.9990 - val_loss: 153.8054
Epoch 33/50
60000/60000 [==============================] - 7s 115us/step - loss: 152.9434 - val_loss: 153.4264
Epoch 34/50
60000/60000 [==============================] - 7s 116us/step - loss: 152.9533 - val_loss: 153.5024
Epoch 35/50
60000/60000 [==============================] - 9s 153us/step - loss: 153.0167 - val_loss: 153.8569
Epoch 36/50
60000/60000 [==============================] - 9s 152us/step - loss: 152.9412 - val_loss: 153.9134
Epoch 37/50
60000/60000 [==============================] - 7s 123us/step - loss: 153.0292 - val_loss: 154.2639
Epoch 38/50
60000/60000 [==============================] - 7s 117us/step - loss: 153.0803 - val_loss: 154.0290
Epoch 39/50
60000/60000 [==============================] - 7s 117us/step - loss: 153.1670 - val_loss: 154.3663
Epoch 40/50
60000/60000 [==============================] - 7s 115us/step - loss: 153.2082 - val_loss: 154.5731
Epoch 41/50
60000/60000 [==============================] - 7s 116us/step - loss: 153.5592 - val_loss: 155.5790
Epoch 42/50
60000/60000 [==============================] - 7s 117us/step - loss: 153.8169 - val_loss: 156.9126
Epoch 43/50
60000/60000 [==============================] - 7s 117us/step - loss: 154.1240 - val_loss: 158.0237
Epoch 44/50
60000/60000 [==============================] - 7s 117us/step - loss: 154.5585 - val_loss: 156.4545
Epoch 45/50
60000/60000 [==============================] - 7s 117us/step - loss: 155.3278 - val_loss: 157.5434
Epoch 46/50
60000/60000 [==============================] - 7s 118us/step - loss: 158.5592 - val_loss: 169.0280
Epoch 47/50
60000/60000 [==============================] - 7s 115us/step - loss: 1593.4144 - val_loss: 2376.2710
Epoch 48/50
60000/60000 [==============================] - 7s 117us/step - loss: 14415.9808 - val_loss: 721.2827
Epoch 49/50
60000/60000 [==============================] - 7s 118us/step - loss: 1791.8892 - val_loss: 148322.9120
Epoch 50/50
60000/60000 [==============================] - 7s 120us/step - loss: 4522.4146 - val_loss: 347087.0158
batch size 25 | MC sample size 5
Train on 60000 samples, validate on 10000 samples
Epoch 1/50
60000/60000 [==============================] - 8s 138us/step - loss: 175.3207 - val_loss: 166.8680
Epoch 2/50
60000/60000 [==============================] - 9s 151us/step - loss: 164.8280 - val_loss: 163.2099
Epoch 3/50
60000/60000 [==============================] - 11s 188us/step - loss: 161.6924 - val_loss: 160.6036
Epoch 4/50
60000/60000 [==============================] - 9s 142us/step - loss: 159.4306 - val_loss: 158.7564
Epoch 5/50
60000/60000 [==============================] - 8s 133us/step - loss: 158.0676 - val_loss: 158.0571
Epoch 6/50
60000/60000 [==============================] - 8s 133us/step - loss: 157.1136 - val_loss: 156.9112
Epoch 7/50
60000/60000 [==============================] - 8s 133us/step - loss: 156.3888 - val_loss: 156.2834
Epoch 8/50
60000/60000 [==============================] - 8s 133us/step - loss: 155.8152 - val_loss: 155.7561
Epoch 9/50
60000/60000 [==============================] - 8s 133us/step - loss: 155.3040 - val_loss: 155.4674
Epoch 10/50
60000/60000 [==============================] - 8s 131us/step - loss: 154.8682 - val_loss: 155.2643
Epoch 11/50
60000/60000 [==============================] - 8s 133us/step - loss: 154.4962 - val_loss: 154.6515
Epoch 12/50
60000/60000 [==============================] - 8s 140us/step - loss: 154.1617 - val_loss: 154.5908
Epoch 13/50
60000/60000 [==============================] - 8s 137us/step - loss: 153.8709 - val_loss: 154.3303
Epoch 14/50
60000/60000 [==============================] - 8s 133us/step - loss: 153.6015 - val_loss: 154.8278
Epoch 15/50
60000/60000 [==============================] - 8s 135us/step - loss: 153.3589 - val_loss: 153.8198
Epoch 16/50
60000/60000 [==============================] - 9s 143us/step - loss: 153.1319 - val_loss: 153.6191
Epoch 17/50
60000/60000 [==============================] - 8s 126us/step - loss: 152.9374 - val_loss: 153.9826
Epoch 18/50
 3500/60000 [&gt;.............................] - ETA: 6s - loss: 151.8664</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">golden_figsize</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">width</span><span class="p">:</span> <span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">width</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">)))</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">golden_figsize</span><span class="p">(</span><span class="mi">6</span><span class="p">))</span>

<span class="c1"># for batch_size in batch_sizes:</span>
<span class="k">for</span> <span class="n">mc_sample_size</span> <span class="ow">in</span> <span class="n">mc_sample_sizes</span><span class="p">:</span>
    
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">histories</span><span class="p">[</span><span class="mi">25</span><span class="p">][</span><span class="n">mc_sample_size</span><span class="p">]</span><span class="o">.</span><span class="n">history</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="s1">'loss'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'MC samples: </span><span class="si">{:2d}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mc_sample_size</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'NELBO'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'# epochs'</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">145</span><span class="p">,</span> <span class="mi">170</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
    </div>
  </div>

        </div>
        <!--End of body content-->
      </div>
    </div>

    <footer id="footer" class="footer">
        
Contents © 2017
<a href="mailto:louistiao@me.com">Louis Tiao</a> - Powered by
<a href="https://getnikola.com" rel="nofollow">Nikola</a>


<span class="pull-right">

  <a class="twitter-follow-button" href="https://twitter.com/louistiao" data-show-count="false" data-show-screen-name="false">
  Follow @louistiao
  </a>

  <a class="github-button" href="https://github.com/ltiao" aria-label="Follow @ltiao on GitHub" data-show-count="false">
  Follow @ltiao
  </a>

  <a href="https://ko-fi.com/A3476EX">
    <object type="image/svg+xml" style="pointer-events: none;" data="https://img.shields.io/badge/Support--yellow.svg?style=social"></object>
  </a>

</span>


            
    </footer>
</div> <!-- /container -->

            <script src="../../assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><!-- Google Analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-43722566-1', 'auto');
  ga('send', 'pageview');

</script><!-- GitHub Buttons --><script async defer src="https://buttons.github.io/buttons.js"></script><!-- Twitter Widgets --><script>window.twttr = (function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0],
    t = window.twttr || {};
  if (d.getElementById(id)) return t;
  js = d.createElement(s);
  js.id = id;
  js.src = "https://platform.twitter.com/widgets.js";
  fjs.parentNode.insertBefore(js, fjs);

  t._e = [];
  t.ready = function(f) {
    t._e.push(f);
  };

  return t;
}(document, "script", "twitter-wjs"));</script>
</body>
</html>
