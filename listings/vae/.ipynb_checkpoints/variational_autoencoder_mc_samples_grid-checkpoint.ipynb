{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.layers import (Input, InputLayer, Dense, Lambda, Layer, \n",
    "                          Add, Multiply)\n",
    "from keras.models import Model, Sequential\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2,\n",
    "                    edgeitems=3,\n",
    "                    linewidth=80,\n",
    "                    suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TensorFlow version: 1.4.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'TensorFlow version: ' + K.tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Constant definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [25, 100] \n",
    "mc_sample_sizes = [1, 5, 25]\n",
    "\n",
    "original_dim = 784\n",
    "latent_dim = 2\n",
    "intermediate_dim = 256\n",
    "epochs = 50\n",
    "epsilon_std = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(y_true, y_pred):\n",
    "    \"\"\" Bernoulli negative log likelihood. \"\"\"\n",
    "\n",
    "    # keras.losses.binary_crossentropy gives the mean\n",
    "    # over the last axis. We require the sum.\n",
    "    return K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDivergenceLayer(Layer):\n",
    "\n",
    "    \"\"\" Identity transform layer that adds KL divergence\n",
    "    to the final model loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(KLDivergenceLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        mu, log_var = inputs\n",
    "\n",
    "        kl_batch = - .5 * K.sum(1 + log_var -\n",
    "                                K.square(mu) -\n",
    "                                K.exp(log_var), axis=-1)\n",
    "\n",
    "        self.add_loss(K.mean(kl_batch), inputs=inputs)\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vae(mc_sample_size, original_dim, latent_dim, intermediate_dim):\n",
    "\n",
    "    x = Input(shape=(original_dim,))\n",
    "    h = Dense(intermediate_dim, activation='relu')(x)\n",
    "\n",
    "    z_mu = Dense(latent_dim)(h)\n",
    "    z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "    z_mu, z_log_var = KLDivergenceLayer()([z_mu, z_log_var])\n",
    "    z_sigma = Lambda(lambda t: K.exp(.5*t))(z_log_var)\n",
    "\n",
    "    eps = Input(tensor=K.random_normal(stddev=epsilon_std,\n",
    "                                       shape=(K.shape(x)[0],\n",
    "                                              mc_sample_size,\n",
    "                                              latent_dim)))\n",
    "\n",
    "    z_eps = Multiply()([z_sigma, eps])\n",
    "    z = Add()([z_mu, z_eps])\n",
    "\n",
    "    decoder = Sequential([\n",
    "        Dense(intermediate_dim, input_dim=latent_dim, activation='relu'),\n",
    "        Dense(original_dim, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    x_mean = decoder(z)\n",
    "\n",
    "    return Model(inputs=[x, eps], outputs=x_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, original_dim) / 255.\n",
    "x_test = x_test.reshape(-1, original_dim) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size 25 | MC sample size 1\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 175.8421 - val_loss: 167.3018\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 165.5251 - val_loss: 164.1144\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 162.9011 - val_loss: 162.0299\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 160.8524 - val_loss: 160.6282\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 159.3570 - val_loss: 158.9316\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 158.3216 - val_loss: 158.2057\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 157.5143 - val_loss: 157.4078\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 156.8400 - val_loss: 157.0826\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 156.2935 - val_loss: 156.1571\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 155.8602 - val_loss: 156.6091\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 155.4742 - val_loss: 156.6663\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 155.1367 - val_loss: 155.1973\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 154.8480 - val_loss: 155.2073\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 154.5779 - val_loss: 155.3731\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 154.3469 - val_loss: 154.7028\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 154.1973 - val_loss: 155.5260\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 153.9781 - val_loss: 154.8877\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 153.8577 - val_loss: 154.8032\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 153.7032 - val_loss: 153.9299\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 153.5557 - val_loss: 154.0591\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 153.4373 - val_loss: 153.8170\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 153.3427 - val_loss: 153.9475\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 153.2269 - val_loss: 153.8917\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 153.1462 - val_loss: 153.6284\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 153.0348 - val_loss: 153.3452\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 152.9652 - val_loss: 153.9279\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 152.8775 - val_loss: 153.9430\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 152.8207 - val_loss: 154.3042\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 152.6848 - val_loss: 154.0990\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 152.6860 - val_loss: 153.3885\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 152.6922 - val_loss: 153.6563\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 152.6492 - val_loss: 154.6584\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 152.5695 - val_loss: 154.0307\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 152.5807 - val_loss: 153.5092\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 152.5250 - val_loss: 153.4744\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 152.5001 - val_loss: 154.0564\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 152.5087 - val_loss: 154.2700\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 152.5314 - val_loss: 154.9365\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 152.5045 - val_loss: 153.7760\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 152.4981 - val_loss: 154.1777\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 152.6465 - val_loss: 153.7983\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 152.5794 - val_loss: 154.8700\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 152.6142 - val_loss: 154.0942\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 152.6253 - val_loss: 155.0538\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 152.7985 - val_loss: 154.9705\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 152.7593 - val_loss: 155.1668\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 152.8709 - val_loss: 154.7914\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 153.0118 - val_loss: 156.0635\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 153.2133 - val_loss: 158.3778\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 153.3307 - val_loss: 158.7638\n",
      "batch size 25 | MC sample size 5\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 176.1818 - val_loss: 167.3606\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 165.4020 - val_loss: 163.8977\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 162.7126 - val_loss: 162.0515\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 160.6405 - val_loss: 160.3235\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 158.9580 - val_loss: 158.4747\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 157.7107 - val_loss: 157.7616\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 156.7769 - val_loss: 157.7819\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 156.0250 - val_loss: 155.8671\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 155.3804 - val_loss: 155.4040\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 154.8584 - val_loss: 155.4528\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 154.4053 - val_loss: 154.7843\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 154.0027 - val_loss: 154.4918\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 153.7002 - val_loss: 154.7157\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 153.3985 - val_loss: 154.0106\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 153.1691 - val_loss: 154.3615\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 152.9600 - val_loss: 154.8249\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 152.7431 - val_loss: 153.3423\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 152.5678 - val_loss: 153.5169\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 152.3860 - val_loss: 153.5342\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 152.2479 - val_loss: 154.3887\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 152.0937 - val_loss: 153.7114\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 151.9730 - val_loss: 153.0029\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 8s 127us/step - loss: 151.7980 - val_loss: 152.7219\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 151.6777 - val_loss: 153.5487\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 151.5209 - val_loss: 153.4073\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 151.4377 - val_loss: 152.9487\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 151.2996 - val_loss: 153.1215\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 151.2229 - val_loss: 152.5450\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 151.1071 - val_loss: 153.1690\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 150.9947 - val_loss: 152.2553\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 150.8764 - val_loss: 152.2232\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 150.7824 - val_loss: 152.3817\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 150.6961 - val_loss: 152.6513\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 150.5910 - val_loss: 151.8752\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 150.5169 - val_loss: 152.0652\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 150.4219 - val_loss: 152.6955\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 150.3752 - val_loss: 153.4268\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 150.3069 - val_loss: 152.8407\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 150.2171 - val_loss: 151.9636\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 150.1624 - val_loss: 151.8540\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 150.0530 - val_loss: 152.0437\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 150.0098 - val_loss: 151.9017\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 149.9730 - val_loss: 152.3978\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 149.9130 - val_loss: 151.8868\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 149.8530 - val_loss: 151.8152\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 149.8249 - val_loss: 152.5391\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 149.7547 - val_loss: 151.5466\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 149.7347 - val_loss: 151.6840\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 149.6728 - val_loss: 152.3136\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 149.6196 - val_loss: 152.3198\n",
      "batch size 25 | MC sample size 15\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 177.4417 - val_loss: 168.5127\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 14s 236us/step - loss: 165.8096 - val_loss: 163.5858\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 161.9040 - val_loss: 160.4281\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 159.5378 - val_loss: 159.1005\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 158.1955 - val_loss: 158.3302\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 157.2369 - val_loss: 157.2345\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 156.4628 - val_loss: 156.5369\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 155.8598 - val_loss: 155.8683\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 155.3562 - val_loss: 156.0605\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 154.9639 - val_loss: 155.6520\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 154.6167 - val_loss: 155.0323\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 154.2851 - val_loss: 155.4045\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 14s 240us/step - loss: 154.0496 - val_loss: 154.8347\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 153.7736 - val_loss: 154.6345\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 153.5586 - val_loss: 155.2900\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 153.3085 - val_loss: 154.1804\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 153.0928 - val_loss: 154.1637\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 152.9170 - val_loss: 154.2141\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 152.7139 - val_loss: 153.8335\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 152.5547 - val_loss: 153.7487\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 152.4131 - val_loss: 153.7508\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 152.2739 - val_loss: 153.2600\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 152.1205 - val_loss: 153.0637\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 15s 244us/step - loss: 151.9848 - val_loss: 153.2081\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 151.8786 - val_loss: 153.3290\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 151.7583 - val_loss: 154.0623\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 151.6499 - val_loss: 153.3039\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 151.5412 - val_loss: 153.8447\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 151.4427 - val_loss: 152.9399\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 151.3447 - val_loss: 153.8290\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 151.2656 - val_loss: 152.8232\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 151.1624 - val_loss: 152.9852\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 151.0790 - val_loss: 153.1620\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 150.9790 - val_loss: 153.0215\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 14s 235us/step - loss: 150.9196 - val_loss: 153.2774\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 150.8477 - val_loss: 153.3272\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 150.7897 - val_loss: 152.9409\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 150.7088 - val_loss: 152.5292\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 150.6477 - val_loss: 153.0897\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 150.5596 - val_loss: 152.8173\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 150.5091 - val_loss: 152.7180\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 150.4506 - val_loss: 153.1099\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 150.3955 - val_loss: 153.3948\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 150.3216 - val_loss: 152.7847\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 150.2294 - val_loss: 152.6257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 150.1858 - val_loss: 152.6878\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 150.1633 - val_loss: 153.0887\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 150.0725 - val_loss: 152.3641\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 150.0503 - val_loss: 152.5620\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 149.9869 - val_loss: 152.7301\n",
      "batch size 25 | MC sample size 25\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 25s 420us/step - loss: 175.1738 - val_loss: 167.1994\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 165.2127 - val_loss: 163.9434\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 162.3047 - val_loss: 161.1742\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 159.9017 - val_loss: 159.4950\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 16s 267us/step - loss: 158.2659 - val_loss: 157.8180\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 157.2021 - val_loss: 157.2713\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 16s 267us/step - loss: 156.4192 - val_loss: 156.4878\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 18s 303us/step - loss: 155.8273 - val_loss: 155.8959\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 16s 262us/step - loss: 155.3069 - val_loss: 155.9010\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 154.8827 - val_loss: 154.9858\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 154.5102 - val_loss: 155.0210\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 154.1637 - val_loss: 154.5844\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 153.8724 - val_loss: 154.6593\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 153.6189 - val_loss: 154.2812\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 153.3652 - val_loss: 154.3575\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 17s 283us/step - loss: 153.1413 - val_loss: 154.3056\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 17s 277us/step - loss: 152.9169 - val_loss: 153.3472\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 152.7272 - val_loss: 153.3392\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 152.5475 - val_loss: 153.4568\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 16s 258us/step - loss: 152.3999 - val_loss: 153.6725\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 152.2503 - val_loss: 153.4581\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 152.0908 - val_loss: 152.9171\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 151.9862 - val_loss: 153.2601\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 151.8679 - val_loss: 153.3406\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 17s 283us/step - loss: 151.7575 - val_loss: 153.1205\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 151.6544 - val_loss: 153.0926\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 151.5499 - val_loss: 152.7653\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 151.4749 - val_loss: 152.6828\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 151.3847 - val_loss: 152.7125\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 151.2923 - val_loss: 152.5259\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 151.2148 - val_loss: 152.6419\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 16s 272us/step - loss: 151.1523 - val_loss: 152.6028\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 18s 293us/step - loss: 151.0880 - val_loss: 153.0801\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 151.0068 - val_loss: 152.7988\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 150.9429 - val_loss: 153.1268\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 150.8844 - val_loss: 152.4512\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 150.8034 - val_loss: 153.4201\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 150.7733 - val_loss: 153.5602\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 150.6979 - val_loss: 152.6793\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 16s 262us/step - loss: 150.6619 - val_loss: 152.3343\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 150.5974 - val_loss: 152.7473\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 16s 262us/step - loss: 150.5832 - val_loss: 153.0138\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 150.5224 - val_loss: 152.6721\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 150.4869 - val_loss: 152.7407\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 150.4268 - val_loss: 152.5680\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 150.3689 - val_loss: 152.4230\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 150.3043 - val_loss: 152.3737\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 150.2660 - val_loss: 152.8623\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 18s 296us/step - loss: 150.2356 - val_loss: 152.4743\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 16s 271us/step - loss: 150.1642 - val_loss: 152.4972\n",
      "batch size 50 | MC sample size 1\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 182.5673 - val_loss: 170.6724\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 168.7884 - val_loss: 166.4067\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 165.2767 - val_loss: 163.2209\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 162.9404 - val_loss: 161.1317\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 161.2104 - val_loss: 159.6516\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 159.8813 - val_loss: 158.8933\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 158.8306 - val_loss: 157.7608\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 157.9271 - val_loss: 157.0627\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 157.2054 - val_loss: 156.4920\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 156.5844 - val_loss: 156.0799\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 156.0222 - val_loss: 155.3471\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 155.5377 - val_loss: 155.2131\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 155.0608 - val_loss: 154.8548\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 154.6844 - val_loss: 154.4224\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 154.3062 - val_loss: 154.4871\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 153.9356 - val_loss: 154.2486\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 153.6225 - val_loss: 153.5941\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 58us/step - loss: 153.2988 - val_loss: 153.2651\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 153.0344 - val_loss: 153.7625\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 152.8068 - val_loss: 152.6892\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 152.5540 - val_loss: 152.8765\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 152.3510 - val_loss: 152.4334\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 152.1127 - val_loss: 152.9271\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 151.9806 - val_loss: 152.9908\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 151.7757 - val_loss: 152.8140\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 151.5944 - val_loss: 152.2479\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 151.4349 - val_loss: 152.3063\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 151.3330 - val_loss: 152.3296\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 151.1259 - val_loss: 151.8729\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 151.0210 - val_loss: 152.0151\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 150.8769 - val_loss: 152.0268\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 150.7609 - val_loss: 152.0502\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 150.6465 - val_loss: 151.7571\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 150.5128 - val_loss: 152.6143\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 150.3864 - val_loss: 151.6148\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 150.2985 - val_loss: 151.6457\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 150.1882 - val_loss: 151.3738\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 150.0642 - val_loss: 151.2116\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 149.9773 - val_loss: 151.2576\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 149.8683 - val_loss: 151.2386\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 149.7776 - val_loss: 151.3272\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 149.7172 - val_loss: 152.4181\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 149.5933 - val_loss: 151.1545\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 149.5403 - val_loss: 151.0815\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 149.4529 - val_loss: 150.9376\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 149.3747 - val_loss: 151.0829\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 149.2812 - val_loss: 151.0107\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 149.2199 - val_loss: 150.7782\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 149.1338 - val_loss: 151.5472\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 149.0642 - val_loss: 150.8971\n",
      "batch size 50 | MC sample size 5\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 183.3004 - val_loss: 171.0988\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 168.8667 - val_loss: 166.7306\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 165.1163 - val_loss: 163.8510\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 162.9077 - val_loss: 162.3187\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 161.2658 - val_loss: 160.8557\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 159.8463 - val_loss: 159.4294\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 158.6429 - val_loss: 158.1571\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 157.6384 - val_loss: 157.8421\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 156.8262 - val_loss: 156.6384\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 156.1081 - val_loss: 155.8629\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 155.4700 - val_loss: 155.7299\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 154.9253 - val_loss: 155.5109\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 154.5201 - val_loss: 154.7908\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 154.1187 - val_loss: 154.4807\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 153.7627 - val_loss: 154.4663\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 153.4495 - val_loss: 154.8351\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 153.1576 - val_loss: 154.1335\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 152.9181 - val_loss: 154.0171\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 152.6745 - val_loss: 153.5961\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 152.4655 - val_loss: 153.3051\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 152.2505 - val_loss: 153.3034\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 152.0532 - val_loss: 153.4599\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 151.8577 - val_loss: 154.5972\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 151.6872 - val_loss: 152.9965\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 151.5351 - val_loss: 153.0501\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 151.3690 - val_loss: 152.8531\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 151.2409 - val_loss: 152.5387\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 151.0991 - val_loss: 152.6732\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 150.9558 - val_loss: 152.4201\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 150.8459 - val_loss: 152.6650\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 150.7102 - val_loss: 152.9167\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 150.5864 - val_loss: 153.0154\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 150.4964 - val_loss: 152.0669\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 150.3779 - val_loss: 152.5458\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 150.3184 - val_loss: 152.1983\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 150.2024 - val_loss: 152.0250\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 150.0881 - val_loss: 152.1904\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 150.0165 - val_loss: 153.6341\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 149.8979 - val_loss: 151.6937\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 149.8105 - val_loss: 151.8800\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 149.7453 - val_loss: 152.0450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 149.6740 - val_loss: 151.9980\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 149.6017 - val_loss: 151.8064\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 149.5113 - val_loss: 151.7681\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 149.4169 - val_loss: 152.1414\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 149.3781 - val_loss: 152.1682\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 149.2813 - val_loss: 152.3033\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 149.2116 - val_loss: 151.6277\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 149.1204 - val_loss: 151.8125\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 149.0436 - val_loss: 151.6923\n",
      "batch size 50 | MC sample size 15\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 181.6949 - val_loss: 169.9180\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 167.3332 - val_loss: 165.7187\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 164.3347 - val_loss: 163.1429\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 162.2183 - val_loss: 161.3448\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 160.4326 - val_loss: 159.8796\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 158.9081 - val_loss: 158.5176\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 157.7965 - val_loss: 157.4304\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 156.9530 - val_loss: 156.9483\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 156.2622 - val_loss: 156.3637\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 155.6764 - val_loss: 156.0169\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 155.1072 - val_loss: 155.4409\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 154.6278 - val_loss: 155.1168\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 154.1886 - val_loss: 154.8295\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 153.7613 - val_loss: 154.4505\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 153.3953 - val_loss: 153.9113\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 153.0708 - val_loss: 153.6117\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 152.7332 - val_loss: 153.9632\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 152.4392 - val_loss: 153.3130\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 152.1966 - val_loss: 152.9809\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 151.9476 - val_loss: 153.2158\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 151.7251 - val_loss: 152.8503\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 151.5210 - val_loss: 152.7532\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 151.3353 - val_loss: 152.8453\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 151.1298 - val_loss: 152.3320\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 150.9808 - val_loss: 153.1944\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 150.8079 - val_loss: 152.2061\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 150.6370 - val_loss: 152.5299\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 150.5337 - val_loss: 152.1004\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 150.3724 - val_loss: 152.2735\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 150.2441 - val_loss: 152.2371\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 150.1402 - val_loss: 151.8924\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 150.0099 - val_loss: 151.6390\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 149.9049 - val_loss: 151.8146\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 149.8029 - val_loss: 151.9462\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 149.6735 - val_loss: 151.6319\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 149.5849 - val_loss: 151.8409\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 149.4945 - val_loss: 151.4798\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 149.4133 - val_loss: 151.8292\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 149.2938 - val_loss: 151.6876\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 149.1916 - val_loss: 151.5679\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 149.1252 - val_loss: 151.5661\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 149.0272 - val_loss: 151.2893\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 148.9702 - val_loss: 151.5044\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 148.9045 - val_loss: 151.3411\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 148.7897 - val_loss: 151.4621\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 148.7181 - val_loss: 151.3123\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 148.6564 - val_loss: 151.6094\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 148.5652 - val_loss: 151.2705\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 11s 175us/step - loss: 148.4983 - val_loss: 151.5869\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 148.4023 - val_loss: 151.5992\n",
      "batch size 50 | MC sample size 25\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e97f776e553a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nfor batch_size in batch_sizes:\\n\\n    for mc_sample_size in mc_sample_sizes:\\n\\n        print('batch size {} | MC sample size {}'\\n              .format(batch_size, mc_sample_size))\\n\\n        x_train_target = np.tile(np.expand_dims(x_train, axis=1),\\n                                 reps=(1, mc_sample_size, 1))\\n        x_test_target = np.tile(np.expand_dims(x_test, axis=1),\\n                                reps=(1, mc_sample_size, 1))\\n\\n        vae = build_vae(mc_sample_size, original_dim, latent_dim, \\n                        intermediate_dim)\\n        vae.compile(optimizer='rmsprop', loss=nll)\\n\\n        histories[batch_size][mc_sample_size] = vae.fit(\\n            x_train,\\n            x_train_target,\\n            shuffle=True,\\n            epochs=epochs,\\n            batch_size=batch_size,\\n            validation_data=(x_test, x_test_target)\\n        )\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/anmoku/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2129\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2130\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2131\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2132\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-61>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/anmoku/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/anmoku/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1096\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/anmoku/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/anmoku/lib/python3.5/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mtile\u001b[0;34m(A, reps)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdim_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnrep\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m//=\u001b[0m \u001b[0mdim_in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "\n",
    "    for mc_sample_size in mc_sample_sizes:\n",
    "\n",
    "        print('batch size {} | MC sample size {}'\n",
    "              .format(batch_size, mc_sample_size))\n",
    "\n",
    "        x_train_target = np.tile(np.expand_dims(x_train, axis=1),\n",
    "                                 reps=(1, mc_sample_size, 1))\n",
    "        x_test_target = np.tile(np.expand_dims(x_test, axis=1),\n",
    "                                reps=(1, mc_sample_size, 1))\n",
    "\n",
    "        vae = build_vae(mc_sample_size, original_dim, latent_dim, \n",
    "                        intermediate_dim)\n",
    "        vae.compile(optimizer='rmsprop', loss=nll)\n",
    "\n",
    "        histories[batch_size][mc_sample_size] = vae.fit(\n",
    "            x_train,\n",
    "            x_train_target,\n",
    "            shuffle=True,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(x_test, x_test_target)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_figsize = lambda width: (width, 2. * width / (1 + np.sqrt(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=golden_figsize(6))\n",
    "\n",
    "# for batch_size in batch_sizes:\n",
    "for mc_sample_size in mc_sample_sizes:\n",
    "    \n",
    "    pd.DataFrame(histories[25][mc_sample_size].history) \\\n",
    "    .plot(y='loss', label='MC samples: {:2d}'.format(mc_sample_size), ax=ax)\n",
    "\n",
    "ax.set_ylabel('NELBO')\n",
    "ax.set_xlabel('# epochs')\n",
    "\n",
    "ax.set_ylim(145, 170)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nikola": {
   "category": "",
   "date": "2017-07-21 18:38:07 UTC+10:00",
   "description": "",
   "link": "",
   "slug": "variational-inference-with-implicit-approximate-inference-models-wip-pt-8",
   "tags": "",
   "title": "Variational Inference with Implicit Approximate Inference Models (WIP Pt. 8)",
   "type": "text"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
