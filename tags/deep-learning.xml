<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Louis Tiao (Posts about deep learning)</title><link>http://louistiao.me/</link><description></description><atom:link href="http://louistiao.me/tags/deep-learning.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2018 &lt;a href="mailto:louistiao@me.com"&gt;Louis Tiao&lt;/a&gt; </copyright><lastBuildDate>Tue, 02 Jan 2018 15:55:44 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Inference in Variational Autoencoders with Different Monte Carlo Sample Sizes (Addendum)</title><link>http://louistiao.me/posts/inference-in-variational-autoencoders-with-different-monte-carlo-sample-sizes-addendum/</link><dc:creator>Louis Tiao</dc:creator><description>&lt;div&gt;&lt;div class="admonition admonition-draft"&gt;
&lt;p class="first admonition-title"&gt;Draft&lt;/p&gt;
&lt;p class="last"&gt;Please do not share or link.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This is a short addendum to a previous post that demonstrates how to perform
&lt;a class="reference external" href="http://louistiao.me/posts/inference-in-variational-autoencoders-with-different-monte-carlo-sample-sizes/"&gt;Inference in Variational Autoencoders with Different Monte Carlo Sample Sizes&lt;/a&gt;
using the basic modular framework we developed in an &lt;a class="reference external" href="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/"&gt;earlier post&lt;/a&gt;.&lt;/p&gt;
&lt;div class="figure align-center"&gt;
&lt;object data="http://louistiao.me/images/vae/nelbo_batch_vs_mc_sample_sizes.svg" style="height: 200px;" type="image/svg+xml"&gt;
../../images/vae/nelbo_batch_vs_mc_sample_sizes.svg&lt;/object&gt;
&lt;p class="caption"&gt;The negative evidence lower bound (ELBO) plotted after each training epoch
for various combinations of batch and Monte Carlo sample sizes.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;a href="http://louistiao.me/posts/inference-in-variational-autoencoders-with-different-monte-carlo-sample-sizes-addendum/"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>bayesian</category><category>deep learning</category><category>keras</category><category>mathjax</category><category>python</category><category>representation learning</category><category>tensorflow</category><category>unsupervised learning</category><category>variational autoencoder</category><category>variational inference</category><guid>http://louistiao.me/posts/inference-in-variational-autoencoders-with-different-monte-carlo-sample-sizes-addendum/</guid><pubDate>Sun, 26 Nov 2017 13:47:03 GMT</pubDate></item><item><title>Inference in Variational Autoencoders with Different Monte Carlo Sample Sizes</title><link>http://louistiao.me/posts/inference-in-variational-autoencoders-with-different-monte-carlo-sample-sizes/</link><dc:creator>Louis Tiao</dc:creator><description>&lt;div&gt;&lt;p&gt;In a &lt;a class="reference external" href="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/"&gt;previous post&lt;/a&gt;,
I demonstrated how to leverage Keras' modular design to implement variational
autoencoders in a way that makes it easy to tweak hyperparameters, adapt to it
to other related models, and extend it to the more sophisticated methods
proposed in the current research.&lt;/p&gt;
&lt;p&gt;Recall that we optimize the generally intractable evidence lower bound (ELBO)
using reparameterization gradients, which approximates the expectation of
gradients with Monte Carlo (MC) samples. In their original paper, Kingma and
Welling (2014) &lt;a class="footnote-reference" href="http://louistiao.me/posts/inference-in-variational-autoencoders-with-different-monte-carlo-sample-sizes/#kingma2014" id="id1"&gt;[1]&lt;/a&gt; remark that an MC sample size of 1 is adequate for
a sufficiently large batch size (~100). Obviously, this is highly dependent on
the problem (more specifically the likelihood). In general, it is important to
experiment with different MC sample sizes and observe the various effects it
has on training stability. In this short post, we demonstrate how to tweak the
MC sample size under our basic framework.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://louistiao.me/posts/inference-in-variational-autoencoders-with-different-monte-carlo-sample-sizes/"&gt;Read more…&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>bayesian</category><category>deep learning</category><category>keras</category><category>mathjax</category><category>python</category><category>representation learning</category><category>tensorflow</category><category>unsupervised learning</category><category>variational autoencoder</category><category>variational inference</category><guid>http://louistiao.me/posts/inference-in-variational-autoencoders-with-different-monte-carlo-sample-sizes/</guid><pubDate>Mon, 20 Nov 2017 12:51:24 GMT</pubDate></item><item><title>Implementing Variational Autoencoders in Keras: Beyond the Quickstart Tutorial</title><link>http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/</link><dc:creator>Louis Tiao</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;a class="reference external" href="https://keras.io/"&gt;Keras&lt;/a&gt; is awesome. It is a very well-designed library that clearly abides by
its &lt;a class="reference external" href="https://keras.io/#guiding-principles"&gt;guiding principles&lt;/a&gt; of modularity and extensibility, enabling us to
easily assemble powerful, complex models from primitive building blocks.
This has been demonstrated in numerous blog posts and tutorials, in particular,
the excellent tutorial on &lt;a class="reference external" href="https://blog.keras.io/building-autoencoders-in-keras.html"&gt;Building Autoencoders in Keras&lt;/a&gt;.
As the name suggests, that tutorial provides examples of how to implement
various kinds of autoencoders in Keras, including the variational autoencoder
(VAE) &lt;a class="footnote-reference" href="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/#kingma2014" id="id1"&gt;[1]&lt;/a&gt;.&lt;/p&gt;
&lt;div class="figure align-center"&gt;
&lt;img alt="../../images/vae/result_combined.png" src="http://louistiao.me/images/vae/result_combined.png"&gt;
&lt;p class="caption"&gt;Visualization of 2D manifold of MNIST digits (left)
and the representation of digits in latent space colored according to their
digit labels (right).&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Like all autoencoders, the variational autoencoder is primarily used for
unsupervised learning of hidden representations.
However, they are fundamentally different to your usual neural network-based
autoencoder in that they approach the problem from a probabilistic perspective.
They specify a joint distribution over the observed and latent variables, and
approximate the intractable posterior conditional density over latent
variables with variational inference, using an &lt;em&gt;inference network&lt;/em&gt;
&lt;a class="footnote-reference" href="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/#inference1" id="id2"&gt;[2]&lt;/a&gt; &lt;a class="footnote-reference" href="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/#inference2" id="id3"&gt;[3]&lt;/a&gt; (or more classically, a &lt;em&gt;recognition model&lt;/em&gt;
&lt;a class="footnote-reference" href="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/#dayan1995" id="id4"&gt;[4]&lt;/a&gt;) to amortize the cost of inference.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/"&gt;Read more…&lt;/a&gt; (24 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>deep learning</category><category>keras</category><category>mathjax</category><category>python</category><category>representation learning</category><category>tensorflow</category><category>unsupervised learning</category><category>variational autoencoder</category><category>variational inference</category><guid>http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/</guid><pubDate>Sun, 22 Oct 2017 14:19:59 GMT</pubDate></item><item><title>Visualizing the Latent Space of Vector Drawings from the Google QuickDraw Dataset with SketchRNN, PCA and t-SNE</title><link>http://louistiao.me/posts/notebooks/visualizing-the-latent-space-of-vector-drawings-from-the-google-quickdraw-dataset-with-sketchrnn-pca-and-t-sne/</link><dc:creator>Louis Tiao</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;img src="http://louistiao.me/sketchrnn/aaron_sheep_tsne.svg" alt="t-SNE Visualization of Sheep Sketches" title="t-SNE Visualization of Sheep Sketches"&gt;&lt;/p&gt;
&lt;p&gt;This is the third part in a series of notes on my exploration of the recently released &lt;a href="https://quickdraw.withgoogle.com/data"&gt;Google QuickDraw dataset&lt;/a&gt; &lt;sup class="footnote-ref" id="fnref-1"&gt;&lt;a href="http://louistiao.me/posts/notebooks/visualizing-the-latent-space-of-vector-drawings-from-the-google-quickdraw-dataset-with-sketchrnn-pca-and-t-sne/#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;, using the concurrently released &lt;a href="http://arxiv.org/abs/1704.03477" title="D. Ha and D. Eck, 'A Neural Representation of Sketch Drawings,' Apr. 2017."&gt;SketchRNN model&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The QuickDraw dataset is curated from the millions of drawings contributed by over 15 million people around the world who participated in the &lt;a href="https://aiexperiments.withgoogle.com/quick-draw"&gt;"Quick, Draw!" A.I. Experiment&lt;/a&gt;, in which they were given the challenge of drawing objects belonging to a particular class (such as "cat") in under 20 seconds.&lt;/p&gt;
&lt;p&gt;SketchRNN is an impressive generative model that was trained to produce vector drawings using this dataset. It was of particular interest to me because it cleverly assembles many of the latest tools and techniques recently developed in machine learning, such as &lt;a href="https://arxiv.org/abs/1312.6114" title="D. P. Kingma and M. Welling, 'Auto-Encoding Variational Bayes,' Dec. 2013."&gt;Variational Autoencoders&lt;/a&gt;, HyperLSTMs (a &lt;a href="https://arxiv.org/abs/1609.09106" title="D. Ha, A. Dai, and Q. V. Le, 'HyperNetworks,' Sep. 2016."&gt;HyperNetwork&lt;/a&gt; for LSTM), &lt;a href="https://arxiv.org/abs/1703.03664" title="S. Reed et al., 'Parallel Multiscale Autoregressive Density Estimation,' Mar. 2017."&gt;Autoregressive models&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/1607.06450" title="J. L. Ba, J. R. Kiros, and G. E. Hinton, 'Layer Normalization,' Jul. 2016."&gt;Layer Normalization&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/1603.05118" title="S. Semeniuta, A. Severyn, and E. Barth, 'Recurrent Dropout without Memory Loss,' Mar. 2016."&gt;Recurrent Dropout&lt;/a&gt;, the &lt;a href="https://arxiv.org/abs/1412.6980" title="D. P. Kingma and J. Ba, 'Adam: A Method for Stochastic Optimization,' Dec. 2014."&gt;Adam optimizer&lt;/a&gt;, among others.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://louistiao.me/posts/notebooks/visualizing-the-latent-space-of-vector-drawings-from-the-google-quickdraw-dataset-with-sketchrnn-pca-and-t-sne/"&gt;Read more…&lt;/a&gt; (12 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>deep learning</category><category>dimensionality reduction</category><category>machine learning</category><category>pca</category><category>python</category><category>t-sne</category><category>tensorflow</category><category>visualization</category><guid>http://louistiao.me/posts/notebooks/visualizing-the-latent-space-of-vector-drawings-from-the-google-quickdraw-dataset-with-sketchrnn-pca-and-t-sne/</guid><pubDate>Sun, 04 Jun 2017 13:17:58 GMT</pubDate></item><item><title>Exploring the Google QuickDraw Dataset with SketchRNN (Part 3)</title><link>http://louistiao.me/notes/exploring-the-google-quickdraw-dataset-with-sketchrnn-part-3/</link><dc:creator>Louis Tiao</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;img src="http://louistiao.me/notes/exploring-the-google-quickdraw-dataset-with-sketchrnn-part-3/sketchrnn/aaron_sheep_tsne.svg" alt="t-SNE Visualization of Sheep Sketches" title="t-SNE Visualization of Sheep Sketches"&gt;&lt;/p&gt;
&lt;p&gt;This is the third part in a series of notes on my exploration of the recently released &lt;a href="https://quickdraw.withgoogle.com/data"&gt;Google QuickDraw dataset&lt;/a&gt; &lt;sup class="footnote-ref" id="fnref-1"&gt;&lt;a href="http://louistiao.me/notes/exploring-the-google-quickdraw-dataset-with-sketchrnn-part-3/#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;, using the concurrently released &lt;a href="http://arxiv.org/abs/1704.03477" title="D. Ha and D. Eck, 'A Neural Representation of Sketch Drawings,' Apr. 2017."&gt;SketchRNN model&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The QuickDraw dataset is curated from the millions of drawings contributed by over 15 million people around the world who participated in the &lt;a href="https://aiexperiments.withgoogle.com/quick-draw"&gt;"Quick, Draw!" A.I. Experiment&lt;/a&gt;, in which they were given the challenge of drawing objects belonging to a particular class (such as "cat") in under 20 seconds.&lt;/p&gt;
&lt;p&gt;SketchRNN is an impressive generative model that was trained to produce vector drawings using this dataset. It was of particular interest to me because it cleverly assembles many of the latest tools and techniques recently developed in machine learning, such as &lt;a href="https://arxiv.org/abs/1312.6114" title="D. P. Kingma and M. Welling, 'Auto-Encoding Variational Bayes,' Dec. 2013."&gt;Variational Autoencoders&lt;/a&gt;, HyperLSTMs (a &lt;a href="https://arxiv.org/abs/1609.09106" title="D. Ha, A. Dai, and Q. V. Le, 'HyperNetworks,' Sep. 2016."&gt;HyperNetwork&lt;/a&gt; for LSTM), &lt;a href="https://arxiv.org/abs/1703.03664" title="S. Reed et al., 'Parallel Multiscale Autoregressive Density Estimation,' Mar. 2017."&gt;Autoregressive models&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/1607.06450" title="J. L. Ba, J. R. Kiros, and G. E. Hinton, 'Layer Normalization,' Jul. 2016."&gt;Layer Normalization&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/1603.05118" title="S. Semeniuta, A. Severyn, and E. Barth, 'Recurrent Dropout without Memory Loss,' Mar. 2016."&gt;Recurrent Dropout&lt;/a&gt;, the &lt;a href="https://arxiv.org/abs/1412.6980" title="D. P. Kingma and J. Ba, 'Adam: A Method for Stochastic Optimization,' Dec. 2014."&gt;Adam optimizer&lt;/a&gt;, among others.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://louistiao.me/notes/exploring-the-google-quickdraw-dataset-with-sketchrnn-part-3/"&gt;Read more…&lt;/a&gt; (12 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>deep learning</category><category>dimensionality reduction</category><category>machine learning</category><category>pca</category><category>python</category><category>t-sne</category><category>tensorflow</category><category>visualization</category><guid>http://louistiao.me/notes/exploring-the-google-quickdraw-dataset-with-sketchrnn-part-3/</guid><pubDate>Sun, 28 May 2017 11:07:23 GMT</pubDate></item></channel></rss>