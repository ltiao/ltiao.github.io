<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Louis Tiao (Posts about python)</title><link>http://louistiao.me/</link><description></description><atom:link href="http://louistiao.me/tags/python.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2017 &lt;a href="mailto:louistiao@me.com"&gt;Louis Tiao&lt;/a&gt; </copyright><lastBuildDate>Mon, 20 Nov 2017 15:04:10 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Inference in Variational Autoencoders with Different Monte Carlo Sample Sizes</title><link>http://louistiao.me/posts/inference-in-variational-autoencoders-with-different-monte-carlo-sample-sizes/</link><dc:creator>Louis Tiao</dc:creator><description>&lt;div&gt;&lt;div class="admonition admonition-draft"&gt;
&lt;p class="first admonition-title"&gt;Draft&lt;/p&gt;
&lt;p class="last"&gt;Please do not share or link.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In a &lt;a class="reference external" href="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/"&gt;previous post&lt;/a&gt;,
I demonstrated how to use leverage Keras' modular design to implement variational
inference in a way that makes it easy to tweak hyperparameters, adapt to related
models, and extend to the more sophisticated methods in the current research.&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_988102aa0bb64b0998a8effa4bcc7c11-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;eps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Input&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mc_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;latent_dim&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;Everything else remains exactly the same. The &lt;tt class="docutils literal"&gt;Multiply&lt;/tt&gt; layer will
automatically broadcast &lt;tt class="docutils literal"&gt;eps&lt;/tt&gt; which has shape
&lt;tt class="docutils literal"&gt;(batch_size, mc_samples, latent_dim)&lt;/tt&gt; with &lt;tt class="docutils literal"&gt;sigma&lt;/tt&gt; which has shape
&lt;tt class="docutils literal"&gt;(batch_size, latent_dim)&lt;/tt&gt; and output shape
&lt;tt class="docutils literal"&gt;(batch_size, mc_samples, latent_dim)&lt;/tt&gt;. Since the subsequent layers do not
operate on the which will then be propagated to the
final output.&lt;/p&gt;
&lt;p&gt;diagram here&lt;/p&gt;
&lt;p&gt;We expand the targets to 3d a array &lt;tt class="docutils literal"&gt;np.expand_dims(x_train, axis=1)&lt;/tt&gt; to be
of shape &lt;tt class="docutils literal"&gt;(batch_size, 1, original_dim)&lt;/tt&gt; so that the loss function can
broadcast with the output with shape &lt;tt class="docutils literal"&gt;(batch_size, mc_samples, original_dim)&lt;/tt&gt;.
It is important to make the distinction between the log likelihood of the mean
over outputs, versus the mean of the log likelihood over the outputs. Since we
require the expected log likelihood, we are interested in the latter.&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_b94ce429bede421c8de9c48c6a4267ad-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;eps_train&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;mc_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;latent_dim&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_b94ce429bede421c8de9c48c6a4267ad-2"&gt;&lt;/a&gt;&lt;span class="n"&gt;eps_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;mc_samples&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;latent_dim&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_b94ce429bede421c8de9c48c6a4267ad-3"&gt;&lt;/a&gt;
&lt;a name="rest_code_b94ce429bede421c8de9c48c6a4267ad-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;vae&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_b94ce429bede421c8de9c48c6a4267ad-5"&gt;&lt;/a&gt;    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;eps_train&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
&lt;a name="rest_code_b94ce429bede421c8de9c48c6a4267ad-6"&gt;&lt;/a&gt;    &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expand_dims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
&lt;a name="rest_code_b94ce429bede421c8de9c48c6a4267ad-7"&gt;&lt;/a&gt;    &lt;span class="n"&gt;shuffle&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_b94ce429bede421c8de9c48c6a4267ad-8"&gt;&lt;/a&gt;    &lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;epochs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_b94ce429bede421c8de9c48c6a4267ad-9"&gt;&lt;/a&gt;    &lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;batch_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;a name="rest_code_b94ce429bede421c8de9c48c6a4267ad-10"&gt;&lt;/a&gt;    &lt;span class="n"&gt;validation_data&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;a name="rest_code_b94ce429bede421c8de9c48c6a4267ad-11"&gt;&lt;/a&gt;        &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;eps_test&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
&lt;a name="rest_code_b94ce429bede421c8de9c48c6a4267ad-12"&gt;&lt;/a&gt;        &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expand_dims&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_b94ce429bede421c8de9c48c6a4267ad-13"&gt;&lt;/a&gt;    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_b94ce429bede421c8de9c48c6a4267ad-14"&gt;&lt;/a&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;For every data point, there are &lt;tt class="docutils literal"&gt;mc_samples&lt;/tt&gt; reconstructions.&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_348a451139a047eab1a100bb6d7c7fa6-1"&gt;&lt;/a&gt;&lt;span class="n"&gt;recons&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;vae&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;x_test&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;eps_test&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;squeeze&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;a name="rest_code_348a451139a047eab1a100bb6d7c7fa6-2"&gt;&lt;/a&gt;
&lt;a name="rest_code_348a451139a047eab1a100bb6d7c7fa6-3"&gt;&lt;/a&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;a name="rest_code_348a451139a047eab1a100bb6d7c7fa6-4"&gt;&lt;/a&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;block&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;recons&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;28&lt;/span&gt;&lt;span class="p"&gt;)))),&lt;/span&gt;
&lt;a name="rest_code_348a451139a047eab1a100bb6d7c7fa6-5"&gt;&lt;/a&gt;           &lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'gray'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_348a451139a047eab1a100bb6d7c7fa6-6"&gt;&lt;/a&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;plot here&lt;/p&gt;&lt;/div&gt;</description><category>bayesian</category><category>deep learning</category><category>keras</category><category>mathjax</category><category>python</category><category>representation learning</category><category>tensorflow</category><category>unsupervised learning</category><category>variational autoencoder</category><category>variational inference</category><guid>http://louistiao.me/posts/inference-in-variational-autoencoders-with-different-monte-carlo-sample-sizes/</guid><pubDate>Mon, 20 Nov 2017 12:51:24 GMT</pubDate></item><item><title>Implementing Variational Autoencoders in Keras: Beyond the Quickstart Tutorial</title><link>http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/</link><dc:creator>Louis Tiao</dc:creator><description>&lt;div&gt;&lt;div class="admonition admonition-draft"&gt;
&lt;p class="first admonition-title"&gt;Draft&lt;/p&gt;
&lt;p class="last"&gt;Please do not share or link.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;a class="reference external" href="https://keras.io/"&gt;Keras&lt;/a&gt; is awesome. It is a very well-designed library that clearly abides by to
its &lt;a class="reference external" href="https://keras.io/#guiding-principles"&gt;guiding principles&lt;/a&gt; of modularity and extensibility and thereby allows us
to easily assemble powerful complex models from primitive building blocks.
This has been demonstrated by many blog posts and tutorials, such as the
excellent tutorial on &lt;a class="reference external" href="https://blog.keras.io/building-autoencoders-in-keras.html"&gt;Building Autoencoders in Keras&lt;/a&gt;.
As the name suggests, that tutorial provides examples of how to implement
various kinds of autoencoders in Keras, including the variational autoencoder
(VAE) &lt;a class="footnote-reference" href="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/#kingma2014" id="id1"&gt;[1]&lt;/a&gt;.&lt;/p&gt;
&lt;div class="figure align-center"&gt;
&lt;img alt="../../images/vae/result_combined.png" src="http://louistiao.me/images/vae/result_combined.png"&gt;
&lt;p class="caption"&gt;Visualization of 2D manifold of MNIST digits (left)
and the representation of digits in latent space colored according to their
digit labels (right).&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Like all autoencoders, the variational autoencoder are primarily used for
unsupervised learning of hidden representations.
However, variational autoencoders are fundamentally different to your standard
neural network-based autoencoder in that they tackle the problem with a
probabilistic approach: by specifying distributions over the observed and
latent variables, and approximating the intractable posterior over the latter
using variational inference with an &lt;em&gt;inference network&lt;/em&gt;
&lt;a class="footnote-reference" href="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/#inference1" id="id2"&gt;[2]&lt;/a&gt; &lt;a class="footnote-reference" href="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/#inference2" id="id3"&gt;[3]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/"&gt;Read moreâ¦&lt;/a&gt; (14 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>deep learning</category><category>keras</category><category>mathjax</category><category>python</category><category>representation learning</category><category>tensorflow</category><category>unsupervised learning</category><category>variational autoencoder</category><category>variational inference</category><guid>http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/</guid><pubDate>Sun, 22 Oct 2017 14:19:59 GMT</pubDate></item><item><title>Visualizing the Latent Space of Vector Drawings from the Google QuickDraw Dataset with SketchRNN, PCA and t-SNE</title><link>http://louistiao.me/posts/notebooks/visualizing-the-latent-space-of-vector-drawings-from-the-google-quickdraw-dataset-with-sketchrnn-pca-and-t-sne/</link><dc:creator>Louis Tiao</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;img src="http://louistiao.me/sketchrnn/aaron_sheep_tsne.svg" alt="t-SNE Visualization of Sheep Sketches" title="t-SNE Visualization of Sheep Sketches"&gt;&lt;/p&gt;
&lt;p&gt;This is the third part in a series of notes on my exploration of the recently released &lt;a href="https://quickdraw.withgoogle.com/data"&gt;Google QuickDraw dataset&lt;/a&gt; &lt;sup class="footnote-ref" id="fnref-1"&gt;&lt;a href="http://louistiao.me/posts/notebooks/visualizing-the-latent-space-of-vector-drawings-from-the-google-quickdraw-dataset-with-sketchrnn-pca-and-t-sne/#fn-1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;, using the concurrently released &lt;a href="http://arxiv.org/abs/1704.03477" title="D. Ha and D. Eck, 'A Neural Representation of Sketch Drawings,' Apr. 2017."&gt;SketchRNN model&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The QuickDraw dataset is curated from the millions of drawings contributed by over 15 million people around the world who participated in the &lt;a href="https://aiexperiments.withgoogle.com/quick-draw"&gt;"Quick, Draw!" A.I. Experiment&lt;/a&gt;, in which they were given the challenge of drawing objects belonging to a particular class (such as "cat") in under 20 seconds.&lt;/p&gt;
&lt;p&gt;SketchRNN is an impressive generative model that was trained to produce vector drawings using this dataset. It was of particular interest to me because it cleverly assembles many of the latest tools and techniques recently developed in machine learning, such as &lt;a href="https://arxiv.org/abs/1312.6114" title="D. P. Kingma and M. Welling, 'Auto-Encoding Variational Bayes,' Dec. 2013."&gt;Variational Autoencoders&lt;/a&gt;, HyperLSTMs (a &lt;a href="https://arxiv.org/abs/1609.09106" title="D. Ha, A. Dai, and Q. V. Le, 'HyperNetworks,' Sep. 2016."&gt;HyperNetwork&lt;/a&gt; for LSTM), &lt;a href="https://arxiv.org/abs/1703.03664" title="S. Reed et al., 'Parallel Multiscale Autoregressive Density Estimation,' Mar. 2017."&gt;Autoregressive models&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/1607.06450" title="J. L. Ba, J. R. Kiros, and G. E. Hinton, 'Layer Normalization,' Jul. 2016."&gt;Layer Normalization&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/1603.05118" title="S. Semeniuta, A. Severyn, and E. Barth, 'Recurrent Dropout without Memory Loss,' Mar. 2016."&gt;Recurrent Dropout&lt;/a&gt;, the &lt;a href="https://arxiv.org/abs/1412.6980" title="D. P. Kingma and J. Ba, 'Adam: A Method for Stochastic Optimization,' Dec. 2014."&gt;Adam optimizer&lt;/a&gt;, among others.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://louistiao.me/posts/notebooks/visualizing-the-latent-space-of-vector-drawings-from-the-google-quickdraw-dataset-with-sketchrnn-pca-and-t-sne/"&gt;Read moreâ¦&lt;/a&gt; (12 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>deep learning</category><category>dimensionality reduction</category><category>machine learning</category><category>pca</category><category>python</category><category>t-sne</category><category>tensorflow</category><category>visualization</category><guid>http://louistiao.me/posts/notebooks/visualizing-the-latent-space-of-vector-drawings-from-the-google-quickdraw-dataset-with-sketchrnn-pca-and-t-sne/</guid><pubDate>Sun, 04 Jun 2017 13:17:58 GMT</pubDate></item><item><title>Exploring the Google QuickDraw Dataset with SketchRNN (Part 3)</title><link>http://louistiao.me/notes/exploring-the-google-quickdraw-dataset-with-sketchrnn-part-3/</link><dc:creator>Louis Tiao</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;img src="http://louistiao.me/notes/exploring-the-google-quickdraw-dataset-with-sketchrnn-part-3/sketchrnn/aaron_sheep_tsne.svg" alt="t-SNE Visualization of Sheep Sketches" title="t-SNE Visualization of Sheep Sketches"&gt;&lt;/p&gt;
&lt;p&gt;This is the third part in a series of notes on my exploration of the recently released &lt;a href="https://quickdraw.withgoogle.com/data"&gt;Google QuickDraw dataset&lt;/a&gt; &lt;sup class="footnote-ref" id="fnref-1"&gt;&lt;a href="http://louistiao.me/notes/exploring-the-google-quickdraw-dataset-with-sketchrnn-part-3/#fn-1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;, using the concurrently released &lt;a href="http://arxiv.org/abs/1704.03477" title="D. Ha and D. Eck, 'A Neural Representation of Sketch Drawings,' Apr. 2017."&gt;SketchRNN model&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The QuickDraw dataset is curated from the millions of drawings contributed by over 15 million people around the world who participated in the &lt;a href="https://aiexperiments.withgoogle.com/quick-draw"&gt;"Quick, Draw!" A.I. Experiment&lt;/a&gt;, in which they were given the challenge of drawing objects belonging to a particular class (such as "cat") in under 20 seconds.&lt;/p&gt;
&lt;p&gt;SketchRNN is an impressive generative model that was trained to produce vector drawings using this dataset. It was of particular interest to me because it cleverly assembles many of the latest tools and techniques recently developed in machine learning, such as &lt;a href="https://arxiv.org/abs/1312.6114" title="D. P. Kingma and M. Welling, 'Auto-Encoding Variational Bayes,' Dec. 2013."&gt;Variational Autoencoders&lt;/a&gt;, HyperLSTMs (a &lt;a href="https://arxiv.org/abs/1609.09106" title="D. Ha, A. Dai, and Q. V. Le, 'HyperNetworks,' Sep. 2016."&gt;HyperNetwork&lt;/a&gt; for LSTM), &lt;a href="https://arxiv.org/abs/1703.03664" title="S. Reed et al., 'Parallel Multiscale Autoregressive Density Estimation,' Mar. 2017."&gt;Autoregressive models&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/1607.06450" title="J. L. Ba, J. R. Kiros, and G. E. Hinton, 'Layer Normalization,' Jul. 2016."&gt;Layer Normalization&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/1603.05118" title="S. Semeniuta, A. Severyn, and E. Barth, 'Recurrent Dropout without Memory Loss,' Mar. 2016."&gt;Recurrent Dropout&lt;/a&gt;, the &lt;a href="https://arxiv.org/abs/1412.6980" title="D. P. Kingma and J. Ba, 'Adam: A Method for Stochastic Optimization,' Dec. 2014."&gt;Adam optimizer&lt;/a&gt;, among others.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://louistiao.me/notes/exploring-the-google-quickdraw-dataset-with-sketchrnn-part-3/"&gt;Read moreâ¦&lt;/a&gt; (12 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>deep learning</category><category>dimensionality reduction</category><category>machine learning</category><category>pca</category><category>python</category><category>t-sne</category><category>tensorflow</category><category>visualization</category><guid>http://louistiao.me/notes/exploring-the-google-quickdraw-dataset-with-sketchrnn-part-3/</guid><pubDate>Sun, 28 May 2017 11:07:23 GMT</pubDate></item><item><title>A Better Approach For Initializing New Nikola Themes (since v7.7.5)</title><link>http://louistiao.me/posts/a-better-approach-for-initializing-new-nikola-themes-since-v775/</link><dc:creator>Louis Tiao</dc:creator><description>&lt;div&gt;&lt;p&gt;A few months ago, I wrote a post on &lt;a class="reference external" href="http://louistiao.me/posts/creating-a-nikola-theme-with-sass-compiled-bootstrap/"&gt;Creating a Nikola theme with Sass-compiled Bootstrap&lt;/a&gt;.
Since then, &lt;a class="reference external" href="https://getnikola.com/changes.html#new-in-v7-7-5"&gt;Nikola 7.7.5&lt;/a&gt; has added several new features which makes it less
tedious to get started with your custom theme.&lt;/p&gt;
&lt;div class="section" id="initializing-the-theme"&gt;
&lt;h2&gt;Initializing the Theme&lt;/h2&gt;
&lt;p&gt;First, I initialize a theme named &lt;tt class="docutils literal"&gt;tiao&lt;/tt&gt;, which automatically creates the
necessary directories and files for me.&lt;/p&gt;
&lt;pre class="code console"&gt;&lt;a name="rest_code_53226ba9e55c4dfcaf3bf4e5164025dd-1"&gt;&lt;/a&gt;&lt;span class="gp"&gt;$&lt;/span&gt; nikola theme --new&lt;span class="o"&gt;=&lt;/span&gt;tiao --engine&lt;span class="o"&gt;=&lt;/span&gt;jinja --parent&lt;span class="o"&gt;=&lt;/span&gt;bootstrap3-jinja
&lt;a name="rest_code_53226ba9e55c4dfcaf3bf4e5164025dd-2"&gt;&lt;/a&gt;&lt;span class="go"&gt;[2016-05-18T02:29:49Z] INFO: theme: Creating theme tiao with parent bootstrap3-jinja and engine jinja in themes/tiao&lt;/span&gt;
&lt;a name="rest_code_53226ba9e55c4dfcaf3bf4e5164025dd-3"&gt;&lt;/a&gt;&lt;span class="go"&gt;[2016-05-18T02:29:49Z] INFO: theme: Created directory themes/tiao&lt;/span&gt;
&lt;a name="rest_code_53226ba9e55c4dfcaf3bf4e5164025dd-4"&gt;&lt;/a&gt;&lt;span class="go"&gt;[2016-05-18T02:29:49Z] INFO: theme: Created file themes/tiao/parent&lt;/span&gt;
&lt;a name="rest_code_53226ba9e55c4dfcaf3bf4e5164025dd-5"&gt;&lt;/a&gt;&lt;span class="go"&gt;[2016-05-18T02:29:49Z] INFO: theme: Created file themes/tiao/engine&lt;/span&gt;
&lt;a name="rest_code_53226ba9e55c4dfcaf3bf4e5164025dd-6"&gt;&lt;/a&gt;&lt;span class="go"&gt;[2016-05-18T02:29:49Z] INFO: theme: Theme themes/tiao created successfully.&lt;/span&gt;
&lt;a name="rest_code_53226ba9e55c4dfcaf3bf4e5164025dd-7"&gt;&lt;/a&gt;&lt;span class="go"&gt;[2016-05-18T02:29:49Z] NOTICE: theme: Remember to set THEME="tiao" in conf.py to use this theme.&lt;/span&gt;
&lt;a name="rest_code_53226ba9e55c4dfcaf3bf4e5164025dd-8"&gt;&lt;/a&gt;
&lt;a name="rest_code_53226ba9e55c4dfcaf3bf4e5164025dd-9"&gt;&lt;/a&gt;&lt;span class="gp"&gt;$&lt;/span&gt; tree themes/tiao
&lt;a name="rest_code_53226ba9e55c4dfcaf3bf4e5164025dd-10"&gt;&lt;/a&gt;&lt;span class="go"&gt;themes/tiao&lt;/span&gt;
&lt;a name="rest_code_53226ba9e55c4dfcaf3bf4e5164025dd-11"&gt;&lt;/a&gt;&lt;span class="go"&gt;âââ engine&lt;/span&gt;
&lt;a name="rest_code_53226ba9e55c4dfcaf3bf4e5164025dd-12"&gt;&lt;/a&gt;&lt;span class="go"&gt;âââ parent&lt;/span&gt;
&lt;a name="rest_code_53226ba9e55c4dfcaf3bf4e5164025dd-13"&gt;&lt;/a&gt;
&lt;a name="rest_code_53226ba9e55c4dfcaf3bf4e5164025dd-14"&gt;&lt;/a&gt;&lt;span class="go"&gt;0 directories, 2 files&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;&lt;a href="http://louistiao.me/posts/a-better-approach-for-initializing-new-nikola-themes-since-v775/"&gt;Read moreâ¦&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><category>nikola</category><category>python</category><guid>http://louistiao.me/posts/a-better-approach-for-initializing-new-nikola-themes-since-v775/</guid><pubDate>Wed, 18 May 2016 02:20:24 GMT</pubDate></item><item><title>Setting up a IPython Parallel Cluster on Amazon EC2 with StarCluster</title><link>http://louistiao.me/posts/setting-up-a-ipython-parallel-cluster-on-amazon-ec2-with-starcluster/</link><dc:creator>Louis Tiao</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;a class="reference external" href="http://star.mit.edu/cluster/"&gt;StarCluster&lt;/a&gt; is an open source cluster-computing toolkit for Amazonâs Elastic
Compute Cloud (EC2) that is designed to automate and simplify the process of
building, configuring, and managing clusters of virtual machines on Amazonâs
EC2 cloud. StarCluster makes it easy to create a cluster computing environment
in the cloud for distributed and parallel computing applications.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://louistiao.me/posts/setting-up-a-ipython-parallel-cluster-on-amazon-ec2-with-starcluster/"&gt;Read moreâ¦&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>amazon aws</category><category>amazon ec2</category><category>distributed computing</category><category>ipython</category><category>pip</category><category>python</category><category>starcluster</category><category>virtualenv</category><guid>http://louistiao.me/posts/setting-up-a-ipython-parallel-cluster-on-amazon-ec2-with-starcluster/</guid><pubDate>Tue, 03 May 2016 12:55:55 GMT</pubDate></item><item><title>Workflow for keeping Nikola config file updated</title><link>http://louistiao.me/posts/workflow-for-keeping-nikola-config-file-updated/</link><dc:creator>Louis Tiao</dc:creator><description>&lt;div&gt;&lt;p&gt;For most, keeping Nikola up-to-date is usually a simple matter of running
something like:&lt;/p&gt;
&lt;pre class="code console"&gt;&lt;a name="rest_code_17d38467420a43f8a3ae7c4f8b230110-1"&gt;&lt;/a&gt;&lt;span class="gp"&gt;$&lt;/span&gt; pip install --upgrade nikola
&lt;/pre&gt;&lt;p&gt;The same goes for its dependencies. However, one important thing that can get
overlooked is the Nikola configuration file for your site (the &lt;tt class="docutils literal"&gt;conf.py&lt;/tt&gt; file
sitting at the root of your Nikola site directory), which is almost always
updated with each major Nikola release.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://louistiao.me/posts/workflow-for-keeping-nikola-config-file-updated/"&gt;Read moreâ¦&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>meld</category><category>nikola</category><category>pip</category><category>python</category><guid>http://louistiao.me/posts/workflow-for-keeping-nikola-config-file-updated/</guid><pubDate>Tue, 29 Mar 2016 00:13:12 GMT</pubDate></item><item><title>Adding __name__ and __doc__ attributes to functools.partial objects</title><link>http://louistiao.me/posts/adding-__name__-and-__doc__-attributes-to-functoolspartial-objects/</link><dc:creator>Louis Tiao</dc:creator><description>&lt;div&gt;&lt;p&gt;The &lt;a class="reference external" href="https://docs.python.org/2/library/functools.html#functools.partial"&gt;partial&lt;/a&gt; function from the &lt;a class="reference external" href="https://docs.python.org/2/library/functools.html"&gt;functools&lt;/a&gt; library is useful for performing
partial function application in Python. There are plenty of guides and
resources on functional programming in Python and this post assumes a reasonable
degree of proficiency with both.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://louistiao.me/posts/adding-__name__-and-__doc__-attributes-to-functoolspartial-objects/"&gt;Read moreâ¦&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>autograd</category><category>functional programming</category><category>functools</category><category>partial function application</category><category>python</category><category>regression</category><guid>http://louistiao.me/posts/adding-__name__-and-__doc__-attributes-to-functoolspartial-objects/</guid><pubDate>Mon, 08 Feb 2016 03:42:56 GMT</pubDate></item><item><title>Python SimpleHTTPServer Recipe: Serve specific directory</title><link>http://louistiao.me/posts/python-simplehttpserver-recipe-serve-specific-directory/</link><dc:creator>Louis Tiao</dc:creator><description>&lt;div&gt;&lt;ul class="simple"&gt;
&lt;li&gt;We need to be able to pass the path to the root of the directory tree we wish
to serve.&lt;/li&gt;
&lt;li&gt;We can only pass arguments to the &lt;tt class="docutils literal"&gt;ServerClass&lt;/tt&gt; and not &lt;tt class="docutils literal"&gt;HandlerClass&lt;/tt&gt;.
Note however that &lt;tt class="docutils literal"&gt;HandlerClass&lt;/tt&gt; is passed as an argument to &lt;tt class="docutils literal"&gt;ServerClass&lt;/tt&gt;
so we should be able to propagate the argument to &lt;tt class="docutils literal"&gt;HandlerClass&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;tt class="docutils literal"&gt;translate_path&lt;/tt&gt; method of &lt;tt class="docutils literal"&gt;SimpleHTTPRequestHandler&lt;/tt&gt; takes the
&lt;tt class="docutils literal"&gt;/&lt;/tt&gt;-separated path specified in the URL and prepends &lt;tt class="docutils literal"&gt;os.getcwd()&lt;/tt&gt; to it.
We just have to instead prepend the  argument we propagated to
&lt;tt class="docutils literal"&gt;SimpleHTTPRequestHandler&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;Lastly we modify the &lt;tt class="docutils literal"&gt;test&lt;/tt&gt; function to take multiple optional arguments
(port and base path) using the excellent module &lt;tt class="docutils literal"&gt;argparse&lt;/tt&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="http://louistiao.me/posts/python-simplehttpserver-recipe-serve-specific-directory/"&gt;Read moreâ¦&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>python</category><guid>http://louistiao.me/posts/python-simplehttpserver-recipe-serve-specific-directory/</guid><pubDate>Thu, 10 Dec 2015 06:38:27 GMT</pubDate></item><item><title>Python SimpleHTTPServer Recipe: Enable CORS</title><link>http://louistiao.me/posts/python-simplehttpserver-recipe-enable-cors/</link><dc:creator>Louis Tiao</dc:creator><description>&lt;div&gt;&lt;p&gt;Create a file, let's call it &lt;tt class="docutils literal"&gt;cors_http_server.py&lt;/tt&gt;, with the code below:&lt;/p&gt;
&lt;pre class="code python"&gt;&lt;a name="rest_code_f3b294913dd34a65b73ef2f8bafea308-1"&gt;&lt;/a&gt;&lt;span class="ch"&gt;#! /usr/bin/env python&lt;/span&gt;
&lt;a name="rest_code_f3b294913dd34a65b73ef2f8bafea308-2"&gt;&lt;/a&gt;
&lt;a name="rest_code_f3b294913dd34a65b73ef2f8bafea308-3"&gt;&lt;/a&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;SimpleHTTPServer&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SimpleHTTPRequestHandler&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt;
&lt;a name="rest_code_f3b294913dd34a65b73ef2f8bafea308-4"&gt;&lt;/a&gt;
&lt;a name="rest_code_f3b294913dd34a65b73ef2f8bafea308-5"&gt;&lt;/a&gt;
&lt;a name="rest_code_f3b294913dd34a65b73ef2f8bafea308-6"&gt;&lt;/a&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;CORSHTTPRequestHandler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;SimpleHTTPRequestHandler&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_f3b294913dd34a65b73ef2f8bafea308-7"&gt;&lt;/a&gt;
&lt;a name="rest_code_f3b294913dd34a65b73ef2f8bafea308-8"&gt;&lt;/a&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;end_headers&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;a name="rest_code_f3b294913dd34a65b73ef2f8bafea308-9"&gt;&lt;/a&gt;        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;send_header&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Access-Control-Allow-Origin'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'*'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_f3b294913dd34a65b73ef2f8bafea308-10"&gt;&lt;/a&gt;        &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;CORSHTTPRequestHandler&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;end_headers&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;a name="rest_code_f3b294913dd34a65b73ef2f8bafea308-11"&gt;&lt;/a&gt;
&lt;a name="rest_code_f3b294913dd34a65b73ef2f8bafea308-12"&gt;&lt;/a&gt;&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;'__main__'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;a name="rest_code_f3b294913dd34a65b73ef2f8bafea308-13"&gt;&lt;/a&gt;    &lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;HandlerClass&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;CORSHTTPRequestHandler&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;p&gt;&lt;a href="http://louistiao.me/posts/python-simplehttpserver-recipe-enable-cors/"&gt;Read moreâ¦&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>cors</category><category>python</category><guid>http://louistiao.me/posts/python-simplehttpserver-recipe-enable-cors/</guid><pubDate>Thu, 10 Dec 2015 04:56:08 GMT</pubDate></item></channel></rss>