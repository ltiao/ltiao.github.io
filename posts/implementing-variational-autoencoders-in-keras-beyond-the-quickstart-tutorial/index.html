<!DOCTYPE html>
<html prefix="
og: http://ogp.me/ns#
article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Implementing Variational Autoencoders in Keras: Beyond the Quickstart Tutorial | Louis Tiao</title>
<link href="../../assets/css/all.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/override_nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/">
<link rel="icon" href="../../favicon_16x16.ico" sizes="16x16">
<link rel="icon" href="../../favicon_32x32.ico" sizes="32x32">
<link rel="icon" href="../../favicon_256x256.ico" sizes="256x256">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script><!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><!--

    /\\\\\\\\\\\\\\\  /\\\\\\\\\\\     /\\\\\\\\\          /\\\\\              
    \///////\\\/////  \/////\\\///    /\\\\\\\\\\\\\      /\\\///\\\           
           \/\\\           \/\\\      /\\\/////////\\\   /\\\/  \///\\\        
            \/\\\           \/\\\     \/\\\       \/\\\  /\\\      \//\\\      
             \/\\\           \/\\\     \/\\\\\\\\\\\\\\\ \/\\\       \/\\\     
              \/\\\           \/\\\     \/\\\/////////\\\ \//\\\      /\\\     
               \/\\\           \/\\\     \/\\\       \/\\\  \///\\\  /\\\      
                \/\\\        /\\\\\\\\\\\ \/\\\       \/\\\    \///\\\\\/      
                 \///        \///////////  \///        \///       \/////       

--><meta name="author" content="Louis Tiao">
<link rel="prev" href="../../notes/working-with-samples-of-distributions-over-convolutional-kernels/" title="Working with Samples of Distributions over Convolutional Kernels" type="text/html">
<link rel="next" href="../../notes/working-with-pandas-multiindex-dataframes-reading-and-writing-to-csv-and-hdf5/" title="Working with Pandas MultiIndex Dataframes: Reading and Writing to CSV and HDF5" type="text/html">
<meta property="og:site_name" content="Louis Tiao">
<meta property="og:title" content="Implementing Variational Autoencoders in Keras: Beyond the Quickstart ">
<meta property="og:url" content="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/">
<meta property="og:description" content="Keras is awesome. It is a very well-designed library that clearly abides by
its guiding principles of modularity and extensibility, enabling us to
easily assemble powerful, complex models from primiti">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2017-10-23T01:19:59+11:00">
<meta property="article:tag" content="deep learning">
<meta property="article:tag" content="keras">
<meta property="article:tag" content="mathjax">
<meta property="article:tag" content="python">
<meta property="article:tag" content="representation learning">
<meta property="article:tag" content="tensorflow">
<meta property="article:tag" content="unsupervised learning">
<meta property="article:tag" content="variational autoencoder">
<meta property="article:tag" content="variational inference">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

  <div class="container">
    <div class="header clearfix">
      <nav><ul class="nav nav-pills pull-right">
<li>
<a href="../../">About</a>
                </li>
<li>
<a href="../../projects/">Projects</a>
                </li>
<li>
<a href="../">Posts</a>
                </li>
<li>
<a href="../../archive.html">Archive</a>

          
        </li>
</ul></nav><a href="http://louistiao.me/">

        <h3 class="text-muted">
          <span id="blog-title">Louis Tiao</span>
        </h3>
      </a>
    </div>

<!-- TODO Figure out what to do with this stuff -->
<!--     <div class="row">

      <ul class="nav nav-pills pull-right">
    <li>
    <a href="/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/index.rst" id="sourcelink">Source</a>
    </li>
          
      </ul>
    </div> -->

    <div id="content" role="main">
      <div class="body-content">
        <!--Body content-->
        <div class="row">
          
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Implementing Variational Autoencoders in Keras: Beyond the Quickstart Tutorial</a></h1>

        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                    Louis Tiao
            </span></p>
            <p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2017-10-23T01:19:59+11:00" itemprop="datePublished" title="2017-10-23 01:19">2017-10-23 01:19</time></a></p>
                <p class="commentline">            <a href="#disqus_thread" data-disqus-identifier="cache/content/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial.html">Comments</a>


                    </p>
<p class="sourceline"><a href="index.rst" class="sourcelink">Source</a></p>

        </div>
        
    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<p><a class="reference external" href="https://keras.io/">Keras</a> is awesome. It is a very well-designed library that clearly abides by
its <a class="reference external" href="https://keras.io/#guiding-principles">guiding principles</a> of modularity and extensibility, enabling us to
easily assemble powerful, complex models from primitive building blocks.
This has been demonstrated in numerous blog posts and tutorials, in particular,
the excellent tutorial on <a class="reference external" href="https://blog.keras.io/building-autoencoders-in-keras.html">Building Autoencoders in Keras</a>.
As the name suggests, that tutorial provides examples of how to implement
various kinds of autoencoders in Keras, including the variational autoencoder
(VAE) <a class="footnote-reference" href="#kingma2014" id="id1">[1]</a>.</p>
<div class="figure align-center">
<img alt="../../images/vae/result_combined.png" src="../../images/vae/result_combined.png"><p class="caption">Visualization of 2D manifold of MNIST digits (left)
and the representation of digits in latent space colored according to their
digit labels (right).</p>
</div>
<p>Like all autoencoders, the variational autoencoder is primarily used for
unsupervised learning of hidden representations.
However, they are fundamentally different to your usual neural network-based
autoencoder in that they approach the problem from a probabilistic perspective.
They specify a joint distribution over the observed and latent variables, and
approximate the intractable posterior conditional density over latent
variables with variational inference, using an <em>inference network</em>
<a class="footnote-reference" href="#inference1" id="id2">[2]</a> <a class="footnote-reference" href="#inference2" id="id3">[3]</a> (or more classically, a <em>recognition model</em>
<a class="footnote-reference" href="#dayan1995" id="id4">[4]</a>) to amortize the cost of inference.</p>
<!-- TEASER_END -->
<p>While the examples in the aforementioned tutorial do well to showcase the
versatility of Keras on a wide range of autoencoder model architectures,
<a class="reference external" href="https://github.com/fchollet/keras/blob/2.1.1/examples/variational_autoencoder.py">its implementation of the variational autoencoder</a> doesn't properly take
advantage of Keras' modular design, making it difficult to generalize and
extend in important ways. As we will see, it relies on implementing custom
layers and constructs that are restricted to a specific instance of
variational autoencoders. This is a shame because when combined, Keras'
building blocks are powerful enough to encapsulate most variants of the
variational autoencoder and more generally, recognition-generative model
combinations for which the generative model belongs to a large family of
<em>deep latent Gaussian models</em> (DLGMs) <a class="footnote-reference" href="#rezende2014" id="id5">[5]</a>.</p>
<p>The goal of this post is to propose a clean and elegant alternative
implementation that takes better advantage of Keras' modular design.
It is not intended as tutorial on variational autoencoders <a class="footnote-reference" href="#id22" id="id6">[*]</a>.
Rather, we study variational autoencoders as a specific case of variational
inference in deep latent Gaussian models with inference networks, and
demonstrate how we can use Keras to implement them in a modular fashion such
that they can be easily adapted to approximate inference in various common
problems with different (non-Gaussian) likelihoods, such as classification with
Bayesian logistic / softmax regression.</p>
<p>This first post will lay the groundwork for a series of future posts that
explore ways to extend this basic modular framework to implement the more
powerful methods proposed in the latest research, such as the normalizing flows
for building richer posterior approximations <a class="footnote-reference" href="#rezende2015" id="id7">[6]</a>, importance weighted
autoencoders <a class="footnote-reference" href="#burda2015" id="id8">[7]</a>, the Gumbel-softmax trick for inference in discrete
latent variables <a class="footnote-reference" href="#jang2016" id="id9">[8]</a>, and even the most recent GAN-based density-ratio
estimation techniques for likelihood-free inference <a class="footnote-reference" href="#mescheder2017" id="id10">[9]</a> <a class="footnote-reference" href="#tran2017" id="id11">[10]</a>.</p>
<div class="section" id="model-specification">
<h2>Model specification</h2>
<p>First, it is important to understand that the variational autoencoder
<a class="reference external" href="http://dustintran.com/blog/variational-auto-encoders-do-not-train-complex-generative-models">is not a way to train generative models</a>.
Rather, the generative model is a component of the variational autoencoder and
is, in general, a deep latent Gaussian model.
In particular, let <span class="math">\(\mathbf{x}\)</span> be a local observed variable and
<span class="math">\(\mathbf{z}\)</span> its corresponding local latent variable, with joint
distribution</p>
<div class="math">
\begin{equation*}
p_{\theta}(\mathbf{x}, \mathbf{z})
= p_{\theta}(\mathbf{x} | \mathbf{z}) p(\mathbf{z}).
\end{equation*}
</div>
<p>In Bayesian modelling, we assume the distribution of observed variables to be
governed by the latent variables. Latent variables are drawn from a prior
density <span class="math">\(p(\mathbf{z})\)</span> and related to the observations though the
likelihood <span class="math">\(p_{\theta}(\mathbf{x} | \mathbf{z})\)</span>.
Deep latent Gaussian models (DLGMs) are a general class of models where the
observed variable is governed by a <em>hierarchy</em> of latent variables, and the
latent variables at each level of the hierarchy are Gaussian <em>a priori</em>
<a class="footnote-reference" href="#rezende2014" id="id12">[5]</a>.</p>
<p>In a typical instance of the variational autoencoder, we have only a single
layer of latent variables with a Normal prior distribution,</p>
<div class="math">
\begin{equation*}
p(\mathbf{z}) = \mathcal{N}(\mathbf{0}, \mathbf{I}).
\end{equation*}
</div>
<p>Now, each local latent variable is related to its corresponding observation
through the likelihood <span class="math">\(p_{\theta}(\mathbf{x} | \mathbf{z})\)</span>, which can
be viewed as a <em>probabilistic</em> decoder. Given a hidden lower-dimensional
representation (or "code") <span class="math">\(\mathbf{z}\)</span>, it "decodes" it into a
<em>distribution</em> over the observation <span class="math">\(\mathbf{x}\)</span>.</p>
<div class="section" id="decoder">
<h3>Decoder</h3>
<p>In this example, we define <span class="math">\(p_{\theta}(\mathbf{x} | \mathbf{z})\)</span> to
be a multivariate Bernoulli whose probabilities are computed from
<span class="math">\(\mathbf{z}\)</span> using a fully-connected neural network with a single hidden
layer,</p>
<div class="math">
\begin{align*}
p_{\theta}(\mathbf{x} | \mathbf{z})
  &amp; = \mathrm{Bern}( \sigma( \mathbf{W}_2 \mathbf{h} + \mathbf{b}_2 ) ), \\
\mathbf{h} &amp; = h(\mathbf{W}_1 \mathbf{z} + \mathbf{b}_1),
\end{align*}
</div>
<p>where <span class="math">\(\sigma\)</span> is the logistic sigmoid function, <span class="math">\(h\)</span> is some
non-linearity, and the model parameters
<span class="math">\(\theta = \{ \mathbf{W}_1, \mathbf{W}_2, \mathbf{b}_1, \mathbf{b}_1 \}\)</span>
consist of the weights and biases of this neural network.</p>
<p>It is straightforward to implement this in Keras with the
<a class="reference external" href="https://keras.io/models/sequential/">Sequential model API</a>:</p>
<pre class="code python"><a name="rest_code_721a9bd5a1ca4c4b8362827a03a7ac53-1"></a><span class="n">decoder</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
<a name="rest_code_721a9bd5a1ca4c4b8362827a03a7ac53-2"></a>    <span class="n">Dense</span><span class="p">(</span><span class="n">intermediate_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span>
<a name="rest_code_721a9bd5a1ca4c4b8362827a03a7ac53-3"></a>          <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
<a name="rest_code_721a9bd5a1ca4c4b8362827a03a7ac53-4"></a>    <span class="n">Dense</span><span class="p">(</span><span class="n">original_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">)</span>
<a name="rest_code_721a9bd5a1ca4c4b8362827a03a7ac53-5"></a><span class="p">])</span>
</pre>
<p>You can view a summary of the model parameters <span class="math">\(\theta\)</span> by calling
<tt class="docutils literal">decoder.summary()</tt>. Additionally, you can produce a high-level diagram of
the network architecture, and optionally the input and output shapes of each
layer using <a class="reference external" href="https://keras.io/visualization/">plot_model</a> from the
<tt class="docutils literal">keras.utils.vis_utils</tt> module. Although our architecture is about as
simple as it gets, it is included in the figure below as an example of what
the diagrams look like.</p>
<div class="figure align-center">
<object data="../../images/vae/decoder.svg" style="height: 200px;" type="image/svg+xml">
../../images/vae/decoder.svg</object>
<p class="caption">Decoder architecture.</p>
</div>
<p>Note that by fixing <span class="math">\(\mathbf{W}_1\)</span>, <span class="math">\(\mathbf{b}_1\)</span> and <span class="math">\(h\)</span>
to be the identity matrix, the zero vector, and the identity function,
respectively (or equivalently dropping the first <tt class="docutils literal">Dense</tt> layer in the snippet
above altogether), we recover <em>logistic factor analysis</em>.
With similarly minor modifications, we can recover other members from the
family of DLGMs, which include <em>non-linear factor analysis</em>,
<em>non-linear Gaussian belief networks</em>, <em>sigmoid belief networks</em>, and many
others <a class="footnote-reference" href="#rezende2014" id="id13">[5]</a>.</p>
<p>Having specified how the probabilities are computed, we can now define the
negative log likelihood of a Bernoulli <span class="math">\(- \log p_{\theta}(\mathbf{x} |
\mathbf{z})\)</span>, which is in fact equivalent to the <a class="reference external" href="https://en.wikipedia.org/wiki/Cross_entropy">binary cross-entropy loss</a>:</p>
<pre class="code python"><a name="rest_code_321ffb13ef904f96bde63b55bb89b59c-1"></a><span class="k">def</span> <span class="nf">nll</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
<a name="rest_code_321ffb13ef904f96bde63b55bb89b59c-2"></a>    <span class="sd">""" Negative log likelihood (Bernoulli). """</span>
<a name="rest_code_321ffb13ef904f96bde63b55bb89b59c-3"></a>
<a name="rest_code_321ffb13ef904f96bde63b55bb89b59c-4"></a>    <span class="c1"># keras.losses.binary_crossentropy gives the mean</span>
<a name="rest_code_321ffb13ef904f96bde63b55bb89b59c-5"></a>    <span class="c1"># over the last axis. we require the sum</span>
<a name="rest_code_321ffb13ef904f96bde63b55bb89b59c-6"></a>    <span class="k">return</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">binary_crossentropy</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre>
<p>As we discuss later, this will not be the loss we ultimately minimize.
However, it will still constitute the data-fitting term of our final loss.</p>
<p>Note this is a valid definition of a <a class="reference external" href="https://keras.io/losses/">Keras loss</a>,
which is required to compile and optimize a model. It is a symbolic function
that returns a scalar for each data-point in <tt class="docutils literal">y_true</tt> and <tt class="docutils literal">y_pred</tt>.
In our example, <tt class="docutils literal">y_pred</tt> will be the output of our <tt class="docutils literal">decoder</tt> network, the
predicted probabilities, and <tt class="docutils literal">y_true</tt> will be the true probabilities.</p>
<div class="admonition tip">
<p class="first admonition-title">Tip</p>
<p>If you are using the TensorFlow backend, you can directly use the
(negative) log probability of <tt class="docutils literal">Bernoulli</tt> from TensorFlow Distributions as
a Keras loss, as I demonstrate in my post on
<a class="reference external" href="../using-negative-log-likelihoods-of-tensorflow-distributions-as-keras-losses/">Using negative log-likelihoods of TensorFlow Distributions as Keras losses</a>.</p>
<p>That is, the following is equivalent to the above definition which instead
uses the <tt class="docutils literal">K.binary_crossentropy</tt> function:</p>
<div class="last"><pre class="code python"><a name="rest_code_3a69743fa40441549b3a9ed262dd2f7c-1"></a><span class="k">def</span> <span class="nf">nll</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
<a name="rest_code_3a69743fa40441549b3a9ed262dd2f7c-2"></a>    <span class="sd">""" Negative log likelihood (Bernoulli). """</span>
<a name="rest_code_3a69743fa40441549b3a9ed262dd2f7c-3"></a>
<a name="rest_code_3a69743fa40441549b3a9ed262dd2f7c-4"></a>    <span class="n">lh</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">tf</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">probs</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<a name="rest_code_3a69743fa40441549b3a9ed262dd2f7c-5"></a>
<a name="rest_code_3a69743fa40441549b3a9ed262dd2f7c-6"></a>    <span class="k">return</span> <span class="o">-</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lh</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">y_true</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="inference">
<h2>Inference</h2>
<p>Having specified the generative process, we would now like to perform inference
on the latent variables and model parameters <span class="math">\(\mathbf{z}\)</span> and
<span class="math">\(\theta\)</span>, respectively.
In particular, our goal is to compute the posterior
<span class="math">\(p_{\theta}(\mathbf{z} | \mathbf{x})\)</span>, the conditional density of the
latent variable <span class="math">\(\mathbf{z}\)</span> given observed variable <span class="math">\(\mathbf{x}\)</span>.
Additionally, we wish to optimize the model parameters <span class="math">\(\theta\)</span> with
respect to the marginal likelihood <span class="math">\(p_{\theta}(\mathbf{x})\)</span>.
Both depend on the marginal likelihood, whose calculation requires marginalizing
out the latent variables <span class="math">\(\mathbf{z}\)</span>. In general, this is computational
intractable, requiring exponential time to compute. Or, it is analytically
intractable and cannot be evaluated in closed-form, as it is in our case
where the Gaussian prior is non-conjugate to the Bernoulli likelihood.</p>
<p>To circumvent this intractability we turn to variational inference, which
formulates inference as an optimization problem. It seeks an approximate
posterior <span class="math">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> closest in Kullback-Leibler
(KL) divergence to the true posterior. More precisely, the approximate posterior
is parameterized by <em>variational parameters</em> <span class="math">\(\phi\)</span>, and we seek a setting
of these parameters that minimizes the aforementioned KL divergence,</p>
<div class="math">
\begin{equation*}
\phi^* = \mathrm{argmin}_{\phi}
\mathrm{KL} [q_{\phi}(\mathbf{z} | \mathbf{x}) \| p_{\theta}(\mathbf{z} | \mathbf{x}) ]
\end{equation*}
</div>
<p>With the luck we've had so far, it shouldn't come as a surprise anymore that
<em>this too</em> is intractable. It also depends on the log marginal likelihood,
whose intractability is the reason we appealed to approximate inference in the
first place. Instead, we <em>maximize</em> an alternative objective function, the
<em>evidence lower bound</em> (ELBO), which is expressed as</p>
<div class="math">
\begin{align*}
\mathrm{ELBO}(q)
&amp;=
\mathbb{E}_{q_{\phi}(\mathbf{z} | \mathbf{x})} [
  \log p_{\theta}(\mathbf{x} | \mathbf{z}) +
  \log p(\mathbf{z}) -
  \log q_{\phi}(\mathbf{z} | \mathbf{x})
] \\
&amp;=
\mathbb{E}_{q_{\phi}(\mathbf{z} | \mathbf{x})} [
  \log p_{\theta}(\mathbf{x} | \mathbf{z})
] - \mathrm{KL} [q_{\phi}(\mathbf{z} | \mathbf{x}) \| p(\mathbf{z}) ].
\end{align*}
</div>
<p>Importantly, the ELBO is a lower bound to the log marginal likelihood.
Therefore, maximizing it with respect to the model parameters <span class="math">\(\theta\)</span>
approximately maximizes the log marginal likelihood.
Additionally, maximizing it with respect to variational parameters <span class="math">\(\phi\)</span>
can be shown to minimize
<span class="math">\(\mathrm{KL} [q_{\phi}(\mathbf{z} | \mathbf{x}) \| p_{\theta}(\mathbf{z} | \mathbf{x}) ]\)</span>.
Also, it turns out that the KL divergence determines the tightness of the lower
bound, where we have equality iff the KL divergence is zero, which happens iff
<span class="math">\(q_{\phi}(\mathbf{z} | \mathbf{x}) = p_{\theta}(\mathbf{z} | \mathbf{x})\)</span>.
Hence, simultaneously maximizing it with respect to <span class="math">\(\theta\)</span> and
<span class="math">\(\phi\)</span> gets us two birds with one stone.</p>
<p>Next we discuss the form of the approximate posterior
<span class="math">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span>, which can be viewed as a
<em>probabilistic</em> encoder. Its role is opposite to that of the decoder.
Given an observation <span class="math">\(\mathbf{x}\)</span>, it "encodes" it into a <em>distribution</em>
over its hidden lower-dimensional representations.</p>
<div class="section" id="encoder">
<h3>Encoder</h3>
<p>For each local observed variable <span class="math">\(\mathbf{x}_n\)</span>, we wish to approximate
the true posterior distribution <span class="math">\(p(\mathbf{z}_n|\mathbf{x}_n)\)</span> over its
corresponding local latent variables <span class="math">\(\mathbf{z}_n\)</span>. A common approach it
to approximate it using a variational distribution
<span class="math">\(q_{\phi_n}(\mathbf{z}_n | \mathbf{x}_n)\)</span> that is a diagonal Gaussian,
where the <em>local</em> variational parameters
<span class="math">\(\phi_n = \{ \mathbf{\mu}_n, \mathbf{\sigma}_n \}\)</span> are the means and
variances of this approximating distribution,</p>
<div class="math">
\begin{equation*}
q_{\phi_n}(\mathbf{z}_n | \mathbf{x}_n) =
\mathcal{N}(
  \mathbf{z}_n |
  \mathbf{\mu}_n,
  \mathrm{diag}(\mathbf{\sigma}_n^2)
).
\end{equation*}
</div>
<p>This approach has a number of shortcomings. First, the number of local
variational parameters we are required to optimize grows with the size of the
dataset. Second, a new set of local variational parameters need to be optimized
for new unseen test points. This is not to mention the strong factorization
assumption we make by specifying diagonal Gaussian distributions as the family
of approximations. We address the first two using an inference network.</p>
<div class="section" id="inference-network">
<h4>Inference network</h4>
<p>We <em>amortize</em> the cost of inference by introducing an <em>inference network</em> which
approximates the local variational parameters <span class="math">\(\phi_n\)</span> for a given local
observed variable <span class="math">\(\textbf{x}_n\)</span>.
For our approximating distribution in particular, given <span class="math">\(\textbf{x}_n\)</span> the
inference network yields two outputs <span class="math">\(\mu_{\phi}(\textbf{x}_n)\)</span> and
<span class="math">\(\sigma_{\phi}(\textbf{x}_n)\)</span>, which we use to approximate its local
variational parameters <span class="math">\(\mathbf{\mu}_n\)</span> and <span class="math">\(\mathbf{\sigma}_n\)</span>,
respectively.
Our approximate posterior distribution now becomes</p>
<div class="math">
\begin{equation*}
q_{\phi}(\mathbf{z}_n | \mathbf{x}_n)
=
\mathcal{N}(
  \mathbf{z}_n |
  \mathbf{\mu}_{\phi}(\mathbf{x}_n),
  \mathrm{diag}(\mathbf{\sigma}_{\phi}^2(\mathbf{x}_n))
).
\end{equation*}
</div>
<p>Instead of learning local variational parameters <span class="math">\(\phi_n\)</span> for each
data-point, we now learn a fixed number of <em>global</em> variational parameters
<span class="math">\(\phi\)</span> which constitute the parameters of the inference network.
Moreover, this approximation allows statistical strength to be shared across
observed data-points and also generalize to unseen test points.</p>
<p>We specify the location and scale of this distribution as the output of an
inference network. For this post, we keep the architecture of the network
simple, with only a single hidden layer and two fully-connected output layers.
Again, this is simple to define in Keras:</p>
<pre class="code python"><a name="rest_code_3595b84fcb7142b5af320c9d45f50c31-1"></a><span class="c1"># input layer</span>
<a name="rest_code_3595b84fcb7142b5af320c9d45f50c31-2"></a><span class="n">x</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">original_dim</span><span class="p">,))</span>
<a name="rest_code_3595b84fcb7142b5af320c9d45f50c31-3"></a>
<a name="rest_code_3595b84fcb7142b5af320c9d45f50c31-4"></a><span class="c1"># hidden layer</span>
<a name="rest_code_3595b84fcb7142b5af320c9d45f50c31-5"></a><span class="n">h</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">intermediate_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<a name="rest_code_3595b84fcb7142b5af320c9d45f50c31-6"></a>
<a name="rest_code_3595b84fcb7142b5af320c9d45f50c31-7"></a><span class="c1"># output layer for mean and log variance</span>
<a name="rest_code_3595b84fcb7142b5af320c9d45f50c31-8"></a><span class="n">z_mu</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">)(</span><span class="n">h</span><span class="p">)</span>
<a name="rest_code_3595b84fcb7142b5af320c9d45f50c31-9"></a><span class="n">z_log_var</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">)(</span><span class="n">h</span><span class="p">)</span>
</pre>
<p>Since this network has multiple outputs, we couldn't use the Sequential model
API as we did for the decoder. Instead, we will resort to the more powerful
<a class="reference external" href="https://keras.io/getting-started/functional-api-guide/">Functional API</a>,
which allows you to implement complex models with shared layers, multiple
inputs, multiple outputs, and so on.</p>
<div class="figure align-center">
<object data="../../images/vae/inference_network.svg" style="height: 200px;" type="image/svg+xml">
../../images/vae/inference_network.svg</object>
<p class="caption">Inference network.</p>
</div>
<p>Note we defined one of the outputs to be the log variance
<span class="math">\(\log \sigma_{\phi}^2(\mathbf{x})\)</span> instead of the standard deviation
<span class="math">\(\sigma_{\phi}(\mathbf{x})\)</span>. This is not only more convenient to work
with but also helps with numerical stability. To recover the latter, we simply
implement the appropriate transformation and encapsulate it in a
<a class="reference external" href="https://keras.io/layers/core/#lambda">Lambda layer</a>.</p>
<pre class="code python"><a name="rest_code_e0fa8dc000504faba999c27f426e8c4f-1"></a><span class="c1"># normalize log variance to std dev</span>
<a name="rest_code_e0fa8dc000504faba999c27f426e8c4f-2"></a><span class="n">z_sigma</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">K</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="n">t</span><span class="p">))(</span><span class="n">z_log_var</span><span class="p">)</span>
</pre>
<p>Before moving on, we give a few words on nomenclature and context.
In the prelude and title of this section, we characterized the approximate
posterior distribution with an inference network as a probabilistic encoder
(analogously to its counterpart, the probabilistic decoder).
Although this is an accurate interpretation, it is a limited one.
Classically, inference networks are known as <em>recognition models</em>, and have now
been used successfully for decades in a number of methods.
When composed end-to-end, the recognition-generative model combination can be
seen as having an autoencoder structure. Indeed, this structure contains the
variational autoencoder as a special case, and the now less fashionable
<em>Helmholtz machine</em> <a class="footnote-reference" href="#dayan1995" id="id14">[4]</a>.
Even more generally, this recognition-generative model combination constitutes
a widely-applicable approach now known as <em>amortized variational inference</em>,
which can be used to perform approximate inference in models that lie beyond
even the large class of deep latent Gaussian models.</p>
<p>Having specified all the ingredients necessary to carry out variational
inference (namely, the prior, likelihood and approximate posterior), we next
focus on finalizing the definition of the (negative) ELBO as our loss function
in Keras. As written earlier, the ELBO can be decomposed into two terms,
<span class="math">\(\mathbb{E}_{q_{\phi}(\mathbf{z} | \mathbf{x})} [ \log p_{\theta}(\mathbf{x} | \mathbf{z}) ]\)</span>
the expected log likelihood (ELL) over <span class="math">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span>,
and <span class="math">\(- \mathrm{KL} [q_{\phi}(\mathbf{z} | \mathbf{x}) \| p(\mathbf{z}) ]\)</span>
the negative KL divergence between prior <span class="math">\(p(\mathbf{z})\)</span> and approximate
posterior <span class="math">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span>. We first turn our attention
to the KL divergence term.</p>
<!-- Note that it is not dependent on the observed data x_i -->
<!-- and does not appear in the expression q_i(z_i). It is only related to x_i -->
<!-- through the ELBO. -->
</div>
<div class="section" id="kl-divergence">
<h4>KL Divergence</h4>
<p>Intuitively, maximizing the negative KL divergence term encourages approximate
posterior densities that place its mass on configurations of the latent
variables which are closest to the prior. Effectively, this regularizes the
complexity of latent space. Now, since both the prior <span class="math">\(p(\mathbf{z})\)</span> and
approximate posterior <span class="math">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span> are Gaussian,
the KL divergence can actually be calculated with the closed-form expression,</p>
<div class="math">
\begin{equation*}
\mathrm{KL} [q_{\phi}(\mathbf{z} | \mathbf{x}) \| p(\mathbf{z}) ]
= - \frac{1}{2} \sum_{k=1}^K \{ 1 + \log \sigma_k^2 - \mu_k^2 - \sigma_k^2 \}
\end{equation*}
</div>
<p>where <span class="math">\(\mu_k\)</span> and <span class="math">\(\sigma_k\)</span> are the <span class="math">\(k\)</span>-th components of
output vectors <span class="math">\(\mathbf{\mu}_{\phi}(\mathbf{x})\)</span> and
<span class="math">\(\mathbf{\sigma}_{\phi}(\mathbf{x})\)</span>, respectively.
This is not too difficult to derive, and I would recommend verifying this as an
exercise. You can also find a derivation in the appendix of Kingma and Welling's
(2014) paper <a class="footnote-reference" href="#kingma2014" id="id15">[1]</a>.</p>
<p>Recall that earlier, we defined the expected log likelihood term of the ELBO as
a Keras loss. We were able to do this since the log likelihood is a function of
the network's final output (the predicted probabilities), so it maps nicely to a
Keras loss. Unfortunately, the same does not apply for the KL divergence term,
which is a function of the network's intermediate layer outputs, the mean <tt class="docutils literal">mu</tt>
and log variance <tt class="docutils literal">log_var</tt>.</p>
<p>We define an auxiliary <a class="reference external" href="https://keras.io/layers/writing-your-own-keras-layers/">custom Keras layer</a>
which takes <tt class="docutils literal">mu</tt>  and <tt class="docutils literal">log_var</tt> as input and simply returns them as output
without modification. We do however explicitly introduce the <a class="reference external" href="https://en.wikipedia.org/wiki/Side_effect_(computer_science)">side-effect</a> of calculating
the KL divergence and adding it to a collection of losses, by calling the method
<tt class="docutils literal">add_loss</tt> <a class="footnote-reference" href="#id23" id="id16">[†]</a>.</p>
<pre class="code python"><a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-1"></a><span class="k">class</span> <span class="nc">KLDivergenceLayer</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-2"></a>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-3"></a>    <span class="sd">""" Identity transform layer that adds KL divergence</span>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-4"></a><span class="sd">    to the final model loss.</span>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-5"></a><span class="sd">    """</span>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-6"></a>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-7"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-8"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">is_placeholder</span> <span class="o">=</span> <span class="bp">True</span>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-9"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">KLDivergenceLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-10"></a>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-11"></a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-12"></a>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-13"></a>        <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span> <span class="o">=</span> <span class="n">inputs</span>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-14"></a>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-15"></a>        <span class="n">kl_batch</span> <span class="o">=</span> <span class="o">-</span> <span class="o">.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">log_var</span> <span class="o">-</span>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-16"></a>                                <span class="n">K</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span> <span class="o">-</span>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-17"></a>                                <span class="n">K</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_var</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-18"></a>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-19"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">kl_batch</span><span class="p">),</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-20"></a>
<a name="rest_code_73e1764a8b784143bd6d91d0b4b17ba8-21"></a>        <span class="k">return</span> <span class="n">inputs</span>
</pre>
<p>Next we feed <tt class="docutils literal">z_mu</tt> and <tt class="docutils literal">z_log_var</tt> through this layer. This needs to take
place before feeding <tt class="docutils literal">z_log_var</tt> through the Lambda layer to recover <tt class="docutils literal">z_sigma</tt>.</p>
<pre class="code python"><a name="rest_code_d914fb63f0c84585a00be5d563a40d83-1"></a><span class="n">z_mu</span><span class="p">,</span> <span class="n">z_log_var</span> <span class="o">=</span> <span class="n">KLDivergenceLayer</span><span class="p">()([</span><span class="n">z_mu</span><span class="p">,</span> <span class="n">z_log_var</span><span class="p">])</span>
</pre>
<p>Now when the Keras model is finally compiled, the collection of losses will be
aggregated and added to the specified Keras loss fwunction to form the loss we
ultimately minimize. If we specify the loss as the negative log-likelihood we
defined earlier (<tt class="docutils literal">nll</tt>), we recover the negative ELBO as the final loss we
minimize.</p>
<!-- TODO -->
<!-- - thought experiment -->
</div>
<div class="section" id="reparameterization-using-merge-layers">
<h4>Reparameterization using Merge Layers</h4>
<p>To perform gradient-based optimization of ELBO with respect to model parameters
<span class="math">\(\theta\)</span> and variational parameters <span class="math">\(\phi\)</span>, we require its gradients
with respect to these parameters, which is generally intractable.
Currently, the dominant approach for circumventing this is by Monte Carlo (MC)
estimation of the gradients. The basic idea is to write the gradient of the
ELBO as an expectation of the gradient, approximate it with MC estimates, then
perform stochastic gradient descent with repeated MC gradient estimates.</p>
<p>There exist a number of estimators based on different variance reduction
techniques. However, MC gradient estimates based on the reparameterization trick,
known as the <em>reparameterization gradients</em>, have be shown to have the lowest
variance among competing estimators for continuous latent variables.
The reparameterization trick is a straightforward change of variables that
expresses the random variable <span class="math">\(\mathbf{z} \sim q_{\phi}(\mathbf{z} | \mathbf{x})\)</span>
as a deterministic transformation <span class="math">\(g_{\phi}\)</span> of another random variable
<span class="math">\(\mathbf{\epsilon}\)</span> and input <span class="math">\(\mathbf{x}\)</span>, with parameters <span class="math">\(\phi\)</span>,</p>
<div class="math">
\begin{equation*}
z = g_{\phi}(\mathbf{x}, \mathbf{\epsilon}), \quad
  \mathbf{\epsilon} \sim p(\mathbf{\epsilon}).
\end{equation*}
</div>
<p>Note that <span class="math">\(p(\mathbf{\epsilon})\)</span> is simpler base distribution which is
parameter-free and independent of <span class="math">\(\mathbf{x}\)</span> or <span class="math">\(\phi\)</span>.
To prevent clutter, we write the ELBO as an expectation of the function
<span class="math">\(f(\mathbf{x}, \mathbf{z}) = \log p_{\theta}(\mathbf{x} , \mathbf{z}) -
\log q_{\phi}(\mathbf{z} | \mathbf{x})\)</span>
over distribution <span class="math">\(q_{\phi}(\mathbf{z} | \mathbf{x})\)</span>.
Now, for any function <span class="math">\(f(\mathbf{x}, \mathbf{z})\)</span>, taking the gradient of
the expectation with respect to <span class="math">\(\phi\)</span>, and substituting all occurrences
of <span class="math">\(\mathbf{z}\)</span> with <span class="math">\(g_{\phi}(\mathbf{x}, \mathbf{\epsilon})\)</span>, we
have</p>
<div class="math">
\begin{align*}
\nabla_{\phi}
\mathbb{E}_{q_{\phi}(\mathbf{z} | \mathbf{x})} [ f(\mathbf{x}, \mathbf{z}) ]
&amp;= \nabla_{\phi} \mathbb{E}_{p(\mathbf{\epsilon})} [
   f(\mathbf{x},
     g_{\phi}(\mathbf{x}, \mathbf{\epsilon}))
] \\
&amp;= \mathbb{E}_{p(\mathbf{\epsilon})} [
 \nabla_{\phi}
 f(\mathbf{x},
   g_{\phi}(\mathbf{x}, \mathbf{\epsilon}))
].
\end{align*}
</div>
<p>In other words, this simple reparameterization allows the gradient and the
expectation to commute, thereby allowing us to take unbiased stochastic
estimates of ELBO gradients by drawing noise samples <span class="math">\(\mathbf{\epsilon}\)</span>
from <span class="math">\(p(\mathbf{\epsilon})\)</span>.</p>
<hr class="docutils">
<p>To recover our diagonal Gaussian approximation
<span class="math">\(q_{\phi}(\mathbf{z}_n | \mathbf{x}_n) =
\mathcal{N}(
\mathbf{z}_n |
\mathbf{\mu}_{\phi}(\mathbf{x}_n),
\mathrm{diag}(\mathbf{\sigma}_{\phi}^2(\mathbf{x}_n)))\)</span>,
we draw noise from the Normal base distribution, and specify a simple
location-scale transformation</p>
<div class="math">
\begin{equation*}
\mathbf{z} =
g_{\phi}(\mathbf{x}, \mathbf{\epsilon}) =
  \mathbf{\mu}_{\phi}(\mathbf{x}) +
  \mathbf{\sigma}_{\phi}(\mathbf{x}) \odot
  \mathbf{\epsilon}, \quad
  \mathbf{\epsilon} \sim
  \mathcal{N}(\mathbf{0}, \mathbf{I})
\end{equation*}
</div>
<p>where <span class="math">\(\mathbf{\mu}_{\phi}(\mathbf{x})\)</span> and
<span class="math">\(\mathbf{\sigma}_{\phi}(\mathbf{x})\)</span> are the outputs of the inference
network with parameter <span class="math">\(\phi\)</span> specified earlier, and <span class="math">\(\odot\)</span> denotes
the elementwise product. In Keras, we explicitly make the noise vector as an
input to the model by defining it as an Input layer. We then implement the
above location-scale transformation using
<a class="reference external" href="https://keras.io/layers/merge/">Merge layers</a>, namely <tt class="docutils literal">Add</tt> and <tt class="docutils literal">Multiply</tt>.</p>
<pre class="code python"><a name="rest_code_b92373c5fc53470a80f782ec458879bf-1"></a><span class="n">eps</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,))</span>
<a name="rest_code_b92373c5fc53470a80f782ec458879bf-2"></a>
<a name="rest_code_b92373c5fc53470a80f782ec458879bf-3"></a><span class="n">z_eps</span> <span class="o">=</span> <span class="n">Multiply</span><span class="p">()([</span><span class="n">z_sigma</span><span class="p">,</span> <span class="n">eps</span><span class="p">])</span>
<a name="rest_code_b92373c5fc53470a80f782ec458879bf-4"></a><span class="n">z</span> <span class="o">=</span> <span class="n">Add</span><span class="p">()([</span><span class="n">z_mu</span><span class="p">,</span> <span class="n">z_eps</span><span class="p">])</span>
</pre>
<div class="figure align-center">
<object data="../../images/vae/reparameterization.svg" style="height: 250px;" type="image/svg+xml">
../../images/vae/reparameterization.svg</object>
<p class="caption">Reparameterization with simple location-scale transformation using Keras
merge layers.</p>
</div>
<p>Since the noise input is drawn from a Normal distribution, we can save from
having to feed this in as input from outside the computation graph by binding a
tensor this Input layer. Specifically, we bind a tensor created using
<tt class="docutils literal">K.random_normal</tt> with the required shape:</p>
<pre class="code python"><a name="rest_code_46492f06a3b041cfaa194e3bb83c63b2-1"></a><span class="n">eps</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">K</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
<a name="rest_code_46492f06a3b041cfaa194e3bb83c63b2-2"></a>                                          <span class="n">latent_dim</span><span class="p">)))</span>
</pre>
<p>While this still needs to be explicitly specified as an input to compile the
model, this input will no longer need to be passed in to methods such as <tt class="docutils literal">fit</tt>,
<tt class="docutils literal">predict</tt>. Samples from this distribution will just be generated within the
computation graph when a dependency of this input is evaluated. See my notes on
<a class="reference external" href="../../notes/keras-constant-input-layers-with-fixed-source-of-stochasticity/">Keras Constant Input Layers with Fixed Source of Stochasticity</a> for more
information.</p>
<div class="figure align-center">
<object data="../../images/vae/encoder.svg" style="height: 500px;" type="image/svg+xml">
../../images/vae/encoder.svg</object>
<p class="caption">Encoder architecture.</p>
</div>
<p>In the <a class="reference external" href="https://github.com/keras-team/keras/blob/2.1.1/examples/variational_autoencoder.py">example implementation</a>, all of this logic is encapsulated in a single
Lambda layer, which simultaneously draws samples from a hard-coded base
distribution and also performs the location-scale transformation.
In contrast, this approach achieves a good level of
<a class="reference external" href="https://en.wikipedia.org/wiki/Loose_coupling">loose coupling</a>
and <a class="reference external" href="https://en.wikipedia.org/wiki/Separation_of_concerns">separation of concerns</a>.
By decoupling the random noise vector from the layer's internal logic and
explicitly making it a model input, we emphasize the fact that all sources of
stochasticity emanate from this input. Then it becomes obvious that a random
sample drawn from a particular approximating distribution is obtained by feeding
this source of stochasticity through a number of successive deterministic
transformations.</p>
<p>For example, we could provide samples drawn from the Uniform distribution as
noise input. By applying a number of deterministic transformations that
constitute the <em>Gumbel-softmax reparameterization trick</em> <a class="footnote-reference" href="#jang2016" id="id17">[8]</a>, we obtain
samples from a Categorical distribution. This allows us to perform approximate
inference on <em>discrete</em> latent variables, and can be implemented in this
framework by adding a dozen or so lines of code!</p>
<!-- .. figure:: ../../images/vae/encoder_full.svg -->
<!-- :height: 500px -->
<!-- :align: center -->
<!-- Full encoder architecture, including auxiliary KL divergence layer. -->
</div>
</div>
<div class="section" id="putting-it-all-together">
<h3>Putting it all together</h3>
<pre class="code python"><a name="rest_code_08c88630887f41398456158920f3df21-1"></a><span class="n">x</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">original_dim</span><span class="p">,))</span>
<a name="rest_code_08c88630887f41398456158920f3df21-2"></a><span class="n">h</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">intermediate_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<a name="rest_code_08c88630887f41398456158920f3df21-3"></a>
<a name="rest_code_08c88630887f41398456158920f3df21-4"></a><span class="n">z_mu</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">)(</span><span class="n">h</span><span class="p">)</span>
<a name="rest_code_08c88630887f41398456158920f3df21-5"></a><span class="n">z_log_var</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">)(</span><span class="n">h</span><span class="p">)</span>
<a name="rest_code_08c88630887f41398456158920f3df21-6"></a>
<a name="rest_code_08c88630887f41398456158920f3df21-7"></a><span class="n">z_mu</span><span class="p">,</span> <span class="n">z_log_var</span> <span class="o">=</span> <span class="n">KLDivergenceLayer</span><span class="p">()([</span><span class="n">z_mu</span><span class="p">,</span> <span class="n">z_log_var</span><span class="p">])</span>
<a name="rest_code_08c88630887f41398456158920f3df21-8"></a><span class="n">z_sigma</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">K</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="n">t</span><span class="p">))(</span><span class="n">z_log_var</span><span class="p">)</span>
<a name="rest_code_08c88630887f41398456158920f3df21-9"></a>
<a name="rest_code_08c88630887f41398456158920f3df21-10"></a><span class="n">eps</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">K</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
<a name="rest_code_08c88630887f41398456158920f3df21-11"></a>                                          <span class="n">latent_dim</span><span class="p">)))</span>
<a name="rest_code_08c88630887f41398456158920f3df21-12"></a><span class="n">z_eps</span> <span class="o">=</span> <span class="n">Multiply</span><span class="p">()([</span><span class="n">z_sigma</span><span class="p">,</span> <span class="n">eps</span><span class="p">])</span>
<a name="rest_code_08c88630887f41398456158920f3df21-13"></a><span class="n">z</span> <span class="o">=</span> <span class="n">Add</span><span class="p">()([</span><span class="n">z_mu</span><span class="p">,</span> <span class="n">z_eps</span><span class="p">])</span>
<a name="rest_code_08c88630887f41398456158920f3df21-14"></a>
<a name="rest_code_08c88630887f41398456158920f3df21-15"></a><span class="n">decoder</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
<a name="rest_code_08c88630887f41398456158920f3df21-16"></a>    <span class="n">Dense</span><span class="p">(</span><span class="n">intermediate_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span>
<a name="rest_code_08c88630887f41398456158920f3df21-17"></a>          <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
<a name="rest_code_08c88630887f41398456158920f3df21-18"></a>    <span class="n">Dense</span><span class="p">(</span><span class="n">original_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">)</span>
<a name="rest_code_08c88630887f41398456158920f3df21-19"></a><span class="p">])</span>
<a name="rest_code_08c88630887f41398456158920f3df21-20"></a>
<a name="rest_code_08c88630887f41398456158920f3df21-21"></a><span class="n">x_pred</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</pre>
<div class="figure align-center">
<object data="../../images/vae/vae_full.svg" style="height: 700px;" type="image/svg+xml">
../../images/vae/vae_full.svg</object>
<p class="caption">Variational autoencoder architecture.</p>
</div>
<pre class="code python"><a name="rest_code_28a10ab155c94cfc90c340ce234ba1ff-1"></a><span class="n">vae</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">eps</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="n">x_pred</span><span class="p">)</span>
<a name="rest_code_28a10ab155c94cfc90c340ce234ba1ff-2"></a><span class="n">vae</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">nll</span><span class="p">)</span>
</pre>
</div>
</div>
<div class="section" id="model-fitting">
<h2>Model fitting</h2>
<div class="section" id="dataset-mnist-digits">
<h3>Dataset: MNIST digits</h3>
<pre class="code python"><a name="rest_code_44167549142c4b3ba6bf77e59bc6c9f8-1"></a><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<a name="rest_code_44167549142c4b3ba6bf77e59bc6c9f8-2"></a><span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">original_dim</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.</span>
<a name="rest_code_44167549142c4b3ba6bf77e59bc6c9f8-3"></a><span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">original_dim</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.</span>
</pre>
<div class="figure align-center">
<object data="../../images/vae/vae_full_shapes.svg" style="height: 700px;" type="image/svg+xml">
../../images/vae/vae_full_shapes.svg</object>
<p class="caption">Variational autoencoder architecture.</p>
</div>
<!-- Model fitting feels less intuitive. The ``vae`` is compiled with ``loss=None`` -->
<!-- explicitly specified which raises a warning. When fit is called, the targets -->
<!-- argument is left unspecified, and the reconstruction loss is optimized through -->
<!-- the `CustomLayer`. This mapping from mathematical problem formulation to code -->
<!-- implementation appears more natural and straightforward. It's easy to understand -->
<!-- at a glance from our call to the ``fit`` method that we're training a -->
<!-- probabilistic auto-encoder. -->
<pre class="code python"><a name="rest_code_98951a2e89594d06b8a26ae2d7314cdc-1"></a><span class="n">vae</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span>
<a name="rest_code_98951a2e89594d06b8a26ae2d7314cdc-2"></a>        <span class="n">x_train</span><span class="p">,</span>
<a name="rest_code_98951a2e89594d06b8a26ae2d7314cdc-3"></a>        <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<a name="rest_code_98951a2e89594d06b8a26ae2d7314cdc-4"></a>        <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
<a name="rest_code_98951a2e89594d06b8a26ae2d7314cdc-5"></a>        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
<a name="rest_code_98951a2e89594d06b8a26ae2d7314cdc-6"></a>        <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">x_test</span><span class="p">))</span>
</pre>
</div>
<div class="section" id="loss-nelbo-convergence">
<h3>Loss (NELBO) Convergence</h3>
<pre class="code python"><a name="rest_code_631299baa47747dda51f16331c9998d8-1"></a><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">hist</span><span class="o">.</span><span class="n">history</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</pre>
<div class="figure align-center">
<object data="../../images/vae/nelbo.svg" style="width: 500px;" type="image/svg+xml">
../../images/vae/nelbo.svg</object>
</div>
</div>
</div>
<div class="section" id="model-evaluation">
<h2>Model evaluation</h2>
<pre class="code python"><a name="rest_code_63ae38dd425c4a8b8ef182575d5a92fa-1"></a><span class="n">encoder</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">z_mu</span><span class="p">)</span>
<a name="rest_code_63ae38dd425c4a8b8ef182575d5a92fa-2"></a>
<a name="rest_code_63ae38dd425c4a8b8ef182575d5a92fa-3"></a><span class="c1"># display a 2D plot of the digit classes in the latent space</span>
<a name="rest_code_63ae38dd425c4a8b8ef182575d5a92fa-4"></a><span class="n">z_test</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<a name="rest_code_63ae38dd425c4a8b8ef182575d5a92fa-5"></a><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<a name="rest_code_63ae38dd425c4a8b8ef182575d5a92fa-6"></a><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">z_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">z_test</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
<a name="rest_code_63ae38dd425c4a8b8ef182575d5a92fa-7"></a>            <span class="n">alpha</span><span class="o">=.</span><span class="mi">4</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'viridis'</span><span class="p">)</span>
<a name="rest_code_63ae38dd425c4a8b8ef182575d5a92fa-8"></a><span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<a name="rest_code_63ae38dd425c4a8b8ef182575d5a92fa-9"></a><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre>
<div class="figure align-center">
<img alt="../../images/vae/result_latent_space.png" src="../../images/vae/result_latent_space.png" style="height: 500px;">
</div>
<pre class="code python"><a name="rest_code_faf4e2a8e8164684bc41b6ead68c1507-1"></a><span class="c1"># display a 2D manifold of the digits</span>
<a name="rest_code_faf4e2a8e8164684bc41b6ead68c1507-2"></a><span class="n">n</span> <span class="o">=</span> <span class="mi">15</span>  <span class="c1"># figure with 15x15 digits</span>
<a name="rest_code_faf4e2a8e8164684bc41b6ead68c1507-3"></a><span class="n">digit_size</span> <span class="o">=</span> <span class="mi">28</span>
<a name="rest_code_faf4e2a8e8164684bc41b6ead68c1507-4"></a>
<a name="rest_code_faf4e2a8e8164684bc41b6ead68c1507-5"></a><span class="c1"># linearly spaced coordinates on the unit square were transformed</span>
<a name="rest_code_faf4e2a8e8164684bc41b6ead68c1507-6"></a><span class="c1"># through the inverse CDF (ppf) of the Gaussian to produce values</span>
<a name="rest_code_faf4e2a8e8164684bc41b6ead68c1507-7"></a><span class="c1"># of the latent variables z, since the prior of the latent space</span>
<a name="rest_code_faf4e2a8e8164684bc41b6ead68c1507-8"></a><span class="c1"># is Gaussian</span>
<a name="rest_code_faf4e2a8e8164684bc41b6ead68c1507-9"></a>
<a name="rest_code_faf4e2a8e8164684bc41b6ead68c1507-10"></a><span class="n">z1</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
<a name="rest_code_faf4e2a8e8164684bc41b6ead68c1507-11"></a><span class="n">z2</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
<a name="rest_code_faf4e2a8e8164684bc41b6ead68c1507-12"></a><span class="n">z_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">z1</span><span class="p">,</span> <span class="n">z2</span><span class="p">))</span>
<a name="rest_code_faf4e2a8e8164684bc41b6ead68c1507-13"></a>
<a name="rest_code_faf4e2a8e8164684bc41b6ead68c1507-14"></a><span class="n">x_pred_grid</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">z_grid</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="n">n</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">))</span> \
<a name="rest_code_faf4e2a8e8164684bc41b6ead68c1507-15"></a>                     <span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">digit_size</span><span class="p">,</span> <span class="n">digit_size</span><span class="p">)</span>
<a name="rest_code_faf4e2a8e8164684bc41b6ead68c1507-16"></a>
<a name="rest_code_faf4e2a8e8164684bc41b6ead68c1507-17"></a><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<a name="rest_code_faf4e2a8e8164684bc41b6ead68c1507-18"></a><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">x_pred_grid</span><span class="p">))),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
<a name="rest_code_faf4e2a8e8164684bc41b6ead68c1507-19"></a><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre>
<div class="figure align-center">
<img alt="../../images/vae/result_manifold.png" src="../../images/vae/result_manifold.png" style="height: 600px;">
</div>
</div>
<div class="section" id="recap">
<h2>Recap</h2>
<p>In this post, we covered the basics of amortized variational inference, looking
at variational autoencoders as a specific example. In particular, we</p>
<ul class="simple">
<li>Implemented the decoder and encoder using the
<a class="reference external" href="https://keras.io/models/sequential/">Sequential</a> and
<a class="reference external" href="https://keras.io/models/model/">functional Model API</a> respectively.</li>
<li>Augmented the final loss with the KL divergence term by writing an auxiliary
<a class="reference external" href="https://keras.io/layers/writing-your-own-keras-layers/">custom layer</a>.</li>
<li>Worked with the log variance for numerical stability, and used a
<a class="reference external" href="https://keras.io/layers/core/#lambda">Lambda layer</a> to transform it to the
standard deviation when necessary.</li>
<li>Explicitly made the noise an Input layer, and implemented the
reparameterization trick using <a class="reference external" href="https://keras.io/layers/merge/">Merge layers</a>.</li>
<li>
<a class="reference external" href="../../notes/keras-constant-input-layers-with-fixed-source-of-stochasticity/">Fixed the noise input to a stochastic tensor</a>, so random
samples are generated <em>within</em> the computation graph.</li>
</ul>
<!-- convolutional --><!-- animation --><!-- MC samples size -->
</div>
<div class="section" id="what-s-next">
<h2>What's next</h2>
<!-- The appeal of this pattern is its simplicity and extensibility -->
<!-- Normalizing flows -->
<!-- We illustrate how to employ the simple Gumbel-Softmax reparameterization to -->
<!-- build a Categorical VAE with discrete latent variables. -->
<p>We can easily extend <tt class="docutils literal">KLDivergenceLayer</tt> to use an auxiliary density ratio
estimator function, instead of evaluating the KL divergence in the closed-form
expression above.
This relaxes the requirement on approximate posterior
<span class="math">\(q(\mathbf{z}|\mathbf{x})\)</span> (and incidentally, also prior
<span class="math">\(p(\mathbf{z})\)</span>) to yield tractable densities, at the cost of maximizing
a cruder estimate of the ELBO.
This is known as Adversarial Variational Bayes <a class="footnote-reference" href="#mescheder2017" id="id20">[9]</a>, and is an
important line of recent research that extends the applicability of variational
inference to arbitrarily expressive implicit probabilistic models with
intractable likelihoods <a class="footnote-reference" href="#tran2017" id="id21">[10]</a>.</p>
</div>
<div class="section" id="footnotes">
<h2>Footnotes</h2>
<table class="docutils footnote" frame="void" id="id22" rules="none">
<colgroup>
<col class="label">
<col>
</colgroup>
<tbody valign="top"><tr>
<td class="label"><a class="fn-backref" href="#id6">[*]</a></td>
<td>
<p class="first">For a complete treatment of variational autoencoders, and variational
inference in general, I highly recommend:</p>
<ul class="last simple">
<li>Jaan Altosaar's blog post, <a class="reference external" href="https://jaan.io/what-is-variational-autoencoder-vae-tutorial/">What is a variational autoencoder?</a>
</li>
<li>Diederik P. Kingma's PhD Thesis,
<a class="reference external" href="https://www.dropbox.com/s/v6ua3d9yt44vgb3/cover_and_thesis.pdf?dl=1">Variational Inference and Deep Learning: A New Synthesis</a>.</li>
</ul>
</td>
</tr></tbody>
</table>
<table class="docutils footnote" frame="void" id="id23" rules="none">
<colgroup>
<col class="label">
<col>
</colgroup>
<tbody valign="top"><tr>
<td class="label"><a class="fn-backref" href="#id16">[†]</a></td>
<td>To support sample weighting (fined-tuning how much each data-point
contributes to the loss), Keras losses are expected returns a scalar for each
data-point in the batch. In contrast, losses appended with the <tt class="docutils literal">add_loss</tt>
method don't support this, and are expected to be a single scalar.
Hence, we calculate the KL divergence for all data-points in the batch and
take the mean before passing it to <tt class="docutils literal">add_loss</tt>.</td>
</tr></tbody>
</table>
</div>
<div class="section" id="references">
<h2>References</h2>
<table class="docutils footnote" frame="void" id="kingma2014" rules="none">
<colgroup>
<col class="label">
<col>
</colgroup>
<tbody valign="top"><tr>
<td class="label">[1]</td>
<td>
<em>(<a class="fn-backref" href="#id1">1</a>, <a class="fn-backref" href="#id15">2</a>)</em> D. P. Kingma and M. Welling,
"Auto-Encoding Variational Bayes,"
in Proceedings of the 2nd International Conference on Learning
Representations (ICLR), 2014.</td>
</tr></tbody>
</table>
<table class="docutils footnote" frame="void" id="inference1" rules="none">
<colgroup>
<col class="label">
<col>
</colgroup>
<tbody valign="top"><tr>
<td class="label"><a class="fn-backref" href="#id2">[2]</a></td>
<td><a class="reference external" href="http://edwardlib.org/tutorials/inference-networks">Edward tutorial on Inference Networks</a></td>
</tr></tbody>
</table>
<table class="docutils footnote" frame="void" id="inference2" rules="none">
<colgroup>
<col class="label">
<col>
</colgroup>
<tbody valign="top"><tr>
<td class="label"><a class="fn-backref" href="#id3">[3]</a></td>
<td>Section "Recognition models and amortised inference" in
<a class="reference external" href="http://blog.shakirm.com/2015/01/variational-inference-tricks-of-the-trade/">Shakir's blog post</a>.</td>
</tr></tbody>
</table>
<table class="docutils footnote" frame="void" id="dayan1995" rules="none">
<colgroup>
<col class="label">
<col>
</colgroup>
<tbody valign="top"><tr>
<td class="label">[4]</td>
<td>
<em>(<a class="fn-backref" href="#id4">1</a>, <a class="fn-backref" href="#id14">2</a>)</em> Dayan, P., Hinton, G. E., Neal, R. M., &amp; Zemel, R. S. (1995).
The Helmholtz machine. Neural Computation, 7(5), 889–904.
<a class="reference external" href="http://doi.org/10.1162/neco.1995.7.5.889">http://doi.org/10.1162/neco.1995.7.5.889</a>
</td>
</tr></tbody>
</table>
<table class="docutils footnote" frame="void" id="rezende2014" rules="none">
<colgroup>
<col class="label">
<col>
</colgroup>
<tbody valign="top"><tr>
<td class="label">[5]</td>
<td>
<em>(<a class="fn-backref" href="#id5">1</a>, <a class="fn-backref" href="#id12">2</a>, <a class="fn-backref" href="#id13">3</a>)</em> Rezende, D. J., Mohamed, S., &amp; Wierstra, D. (2014).
"Stochastic backpropagation and approximate inference in deep generative models,"
in Proceedings of The 31st International Conference on Machine Learning, 2014,
(Vol. 32, pp. 1278–1286). Bejing, China: PMLR. <a class="reference external" href="http://doi.org/10.1051/0004-6361/201527329">http://doi.org/10.1051/0004-6361/201527329</a>
</td>
</tr></tbody>
</table>
<table class="docutils footnote" frame="void" id="rezende2015" rules="none">
<colgroup>
<col class="label">
<col>
</colgroup>
<tbody valign="top"><tr>
<td class="label"><a class="fn-backref" href="#id7">[6]</a></td>
<td>D. Rezende and S. Mohamed,
"Variational Inference with Normalizing Flows,"
in Proceedings of the 32nd International Conference on Machine Learning, 2015,
vol. 37, pp. 1530–1538.</td>
</tr></tbody>
</table>
<table class="docutils footnote" frame="void" id="burda2015" rules="none">
<colgroup>
<col class="label">
<col>
</colgroup>
<tbody valign="top"><tr>
<td class="label"><a class="fn-backref" href="#id8">[7]</a></td>
<td>Y. Burda, R. Grosse, and R. Salakhutdinov,
"Importance Weighted Autoencoders,"
in Proceedings of the 3rd International Conference on Learning
Representations (ICLR), 2015.</td>
</tr></tbody>
</table>
<table class="docutils footnote" frame="void" id="jang2016" rules="none">
<colgroup>
<col class="label">
<col>
</colgroup>
<tbody valign="top"><tr>
<td class="label">[8]</td>
<td>
<em>(<a class="fn-backref" href="#id9">1</a>, <a class="fn-backref" href="#id17">2</a>)</em> E. Jang, S. Gu, and B. Poole,
"Categorical Reparameterization with Gumbel-Softmax," Nov. 2016.
in Proceedings of the 5th International Conference on Learning
Representations (ICLR), 2017.</td>
</tr></tbody>
</table>
<table class="docutils footnote" frame="void" id="mescheder2017" rules="none">
<colgroup>
<col class="label">
<col>
</colgroup>
<tbody valign="top"><tr>
<td class="label">[9]</td>
<td>
<em>(<a class="fn-backref" href="#id10">1</a>, <a class="fn-backref" href="#id20">2</a>)</em> L. Mescheder, S. Nowozin, and A. Geiger,
"Adversarial Variational Bayes: Unifying Variational Autoencoders and
Generative Adversarial Networks,"
in Proceedings of the 34th International Conference on Machine Learning, 2017,
vol. 70, pp. 2391–2400.</td>
</tr></tbody>
</table>
<table class="docutils footnote" frame="void" id="tran2017" rules="none">
<colgroup>
<col class="label">
<col>
</colgroup>
<tbody valign="top"><tr>
<td class="label">[10]</td>
<td>
<em>(<a class="fn-backref" href="#id11">1</a>, <a class="fn-backref" href="#id21">2</a>)</em> D. Tran, R. Ranganath, and D. Blei,
"Hierarchical Implicit Models and Likelihood-Free Variational Inference,"
<em>to appear in</em> Advances in Neural Information Processing Systems 31, 2017.</td>
</tr></tbody>
</table>
</div>
<div class="section" id="appendix">
<h2>Appendix</h2>
<p>Below, you can find:</p>
<ul class="simple">
<li>The <a class="reference external" href="../../listings/vae/variational_autoencoder.ipynb.html">accompanying Jupyter Notebook</a> used to generate the diagrams and plots
in this post.</li>
<li>The above snippets combined in a single executable Python file:</li>
</ul>
<p><a class="reference external" href="../../listings/vae/variational_autoencoder.py.html">vae/variational_autoencoder.py</a>  <a class="reference external" href="../../listings/vae/variational_autoencoder.py">(Source)</a></p>
<pre class="code python"><a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-2"></a><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-3"></a><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-4"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-5"></a><span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-6"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-7"></a><span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">,</span> <span class="n">Layer</span><span class="p">,</span> <span class="n">Add</span><span class="p">,</span> <span class="n">Multiply</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-8"></a><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span><span class="p">,</span> <span class="n">Sequential</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-9"></a><span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-10"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-11"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-12"></a><span class="n">original_dim</span> <span class="o">=</span> <span class="mi">784</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-13"></a><span class="n">intermediate_dim</span> <span class="o">=</span> <span class="mi">256</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-14"></a><span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">2</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-15"></a><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-16"></a><span class="n">epochs</span> <span class="o">=</span> <span class="mi">50</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-17"></a><span class="n">epsilon_std</span> <span class="o">=</span> <span class="mf">1.0</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-18"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-19"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-20"></a><span class="k">def</span> <span class="nf">nll</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-21"></a>    <span class="sd">""" Negative log likelihood (Bernoulli). """</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-22"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-23"></a>    <span class="c1"># keras.losses.binary_crossentropy gives the mean</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-24"></a>    <span class="c1"># over the last axis. we require the sum</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-25"></a>    <span class="k">return</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">binary_crossentropy</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-26"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-27"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-28"></a><span class="k">class</span> <span class="nc">KLDivergenceLayer</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-29"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-30"></a>    <span class="sd">""" Identity transform layer that adds KL divergence</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-31"></a><span class="sd">    to the final model loss.</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-32"></a><span class="sd">    """</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-33"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-34"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-35"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">is_placeholder</span> <span class="o">=</span> <span class="bp">True</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-36"></a>        <span class="nb">super</span><span class="p">(</span><span class="n">KLDivergenceLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-37"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-38"></a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-39"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-40"></a>        <span class="n">mu</span><span class="p">,</span> <span class="n">log_var</span> <span class="o">=</span> <span class="n">inputs</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-41"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-42"></a>        <span class="n">kl_batch</span> <span class="o">=</span> <span class="o">-</span> <span class="o">.</span><span class="mi">5</span> <span class="o">*</span> <span class="n">K</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">log_var</span> <span class="o">-</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-43"></a>                                <span class="n">K</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span> <span class="o">-</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-44"></a>                                <span class="n">K</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_var</span><span class="p">),</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-45"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-46"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">kl_batch</span><span class="p">),</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-47"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-48"></a>        <span class="k">return</span> <span class="n">inputs</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-49"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-50"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-51"></a><span class="n">decoder</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-52"></a>    <span class="n">Dense</span><span class="p">(</span><span class="n">intermediate_dim</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-53"></a>    <span class="n">Dense</span><span class="p">(</span><span class="n">original_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">)</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-54"></a><span class="p">])</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-55"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-56"></a><span class="n">x</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">original_dim</span><span class="p">,))</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-57"></a><span class="n">h</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">intermediate_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-58"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-59"></a><span class="n">z_mu</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">)(</span><span class="n">h</span><span class="p">)</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-60"></a><span class="n">z_log_var</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">)(</span><span class="n">h</span><span class="p">)</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-61"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-62"></a><span class="n">z_mu</span><span class="p">,</span> <span class="n">z_log_var</span> <span class="o">=</span> <span class="n">KLDivergenceLayer</span><span class="p">()([</span><span class="n">z_mu</span><span class="p">,</span> <span class="n">z_log_var</span><span class="p">])</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-63"></a><span class="n">z_sigma</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">K</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="n">t</span><span class="p">))(</span><span class="n">z_log_var</span><span class="p">)</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-64"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-65"></a><span class="n">eps</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">K</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span><span class="n">stddev</span><span class="o">=</span><span class="n">epsilon_std</span><span class="p">,</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-66"></a>                                   <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">latent_dim</span><span class="p">)))</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-67"></a><span class="n">z_eps</span> <span class="o">=</span> <span class="n">Multiply</span><span class="p">()([</span><span class="n">z_sigma</span><span class="p">,</span> <span class="n">eps</span><span class="p">])</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-68"></a><span class="n">z</span> <span class="o">=</span> <span class="n">Add</span><span class="p">()([</span><span class="n">z_mu</span><span class="p">,</span> <span class="n">z_eps</span><span class="p">])</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-69"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-70"></a><span class="n">x_pred</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-71"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-72"></a><span class="n">vae</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">eps</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="n">x_pred</span><span class="p">)</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-73"></a><span class="n">vae</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">nll</span><span class="p">)</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-74"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-75"></a><span class="c1"># train the VAE on MNIST digits</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-76"></a><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-77"></a><span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">original_dim</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-78"></a><span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">original_dim</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-79"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-80"></a><span class="n">vae</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-81"></a>        <span class="n">x_train</span><span class="p">,</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-82"></a>        <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-83"></a>        <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-84"></a>        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-85"></a>        <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">x_test</span><span class="p">))</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-86"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-87"></a><span class="n">encoder</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">z_mu</span><span class="p">)</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-88"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-89"></a><span class="c1"># display a 2D plot of the digit classes in the latent space</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-90"></a><span class="n">z_test</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-91"></a><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-92"></a><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">z_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">z_test</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-93"></a>            <span class="n">alpha</span><span class="o">=.</span><span class="mi">4</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'viridis'</span><span class="p">)</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-94"></a><span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-95"></a><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-96"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-97"></a><span class="c1"># display a 2D manifold of the digits</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-98"></a><span class="n">n</span> <span class="o">=</span> <span class="mi">15</span>  <span class="c1"># figure with 15x15 digits</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-99"></a><span class="n">digit_size</span> <span class="o">=</span> <span class="mi">28</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-100"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-101"></a><span class="c1"># linearly spaced coordinates on the unit square were transformed</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-102"></a><span class="c1"># through the inverse CDF (ppf) of the Gaussian to produce values</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-103"></a><span class="c1"># of the latent variables z, since the prior of the latent space</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-104"></a><span class="c1"># is Gaussian</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-105"></a><span class="n">u_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-106"></a>                               <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="n">n</span><span class="p">)))</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-107"></a><span class="n">z_grid</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">u_grid</span><span class="p">)</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-108"></a><span class="n">x_decoded</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">z_grid</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n</span><span class="o">*</span><span class="n">n</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-109"></a><span class="n">x_decoded</span> <span class="o">=</span> <span class="n">x_decoded</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">digit_size</span><span class="p">,</span> <span class="n">digit_size</span><span class="p">)</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-110"></a>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-111"></a><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-112"></a><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">block</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">x_decoded</span><span class="p">))),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">)</span>
<a name="rest_code_800ae9bcd9964911b1dc63cdb1de3866-113"></a><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre>
</div>
</div>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../tags/deep-learning/" rel="tag">deep learning</a></li>
            <li><a class="tag p-category" href="../../tags/keras/" rel="tag">keras</a></li>
            <li><a class="tag p-category" href="../../tags/python/" rel="tag">python</a></li>
            <li><a class="tag p-category" href="../../tags/representation-learning/" rel="tag">representation learning</a></li>
            <li><a class="tag p-category" href="../../tags/tensorflow/" rel="tag">tensorflow</a></li>
            <li><a class="tag p-category" href="../../tags/unsupervised-learning/" rel="tag">unsupervised learning</a></li>
            <li><a class="tag p-category" href="../../tags/variational-autoencoder/" rel="tag">variational autoencoder</a></li>
            <li><a class="tag p-category" href="../../tags/variational-inference/" rel="tag">variational inference</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../../notes/working-with-samples-of-distributions-over-convolutional-kernels/" rel="prev" title="Working with Samples of Distributions over Convolutional Kernels">Previous post</a>
            </li>
            <li class="next">
                <a href="../../notes/working-with-pandas-multiindex-dataframes-reading-and-writing-to-csv-and-hdf5/" rel="next" title="Working with Pandas MultiIndex Dataframes: Reading and Writing to CSV and HDF5">Next post</a>
            </li>
        </ul></nav></aside><section class="comments hidden-print"><h2>Comments</h2>
                        <div id="disqus_thread"></div>
        <script>
        var disqus_shortname ="ltiao",
            disqus_url="http://louistiao.me/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial/",
        disqus_title="Implementing Variational Autoencoders in Keras: Beyond the Quickstart Tutorial",
        disqus_identifier="cache/content/posts/implementing-variational-autoencoders-in-keras-beyond-the-quickstart-tutorial.html",
        disqus_config = function () {
            this.language = "en";
        };
        (function() {
            var dsq = document.createElement('script'); dsq.async = true;
            dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
    <a href="https://disqus.com" class="dsq-brlink" rel="nofollow">Comments powered by <span class="logo-disqus">Disqus</span></a>


        </section><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha256-SDRP1VVYu+tgAGKhddBSl5+ezofHKZeI+OzxakbIe/Y=" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script></article><script>var disqus_shortname="ltiao";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script>
</div>
        <!--End of body content-->
      </div>
    </div>

    <footer id="footer" class="footer">
        
Contents © 2017
<a href="mailto:louistiao@me.com">Louis Tiao</a> - Powered by
<a href="https://getnikola.com" rel="nofollow">Nikola</a>


<span class="pull-right">

  <a class="twitter-follow-button" href="https://twitter.com/louistiao" data-show-count="false" data-show-screen-name="false">
  Follow @louistiao
  </a>

  <a class="github-button" href="https://github.com/ltiao" aria-label="Follow @ltiao on GitHub" data-show-count="false">
  Follow @ltiao
  </a>

  <a href="https://ko-fi.com/A3476EX">
    <object type="image/svg+xml" style="pointer-events: none;" data="https://img.shields.io/badge/Support--yellow.svg?style=social"></object>
  </a>

</span>


            
    </footer>
</div> <!-- /container -->

            <script src="../../assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><!-- Google Analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-43722566-1', 'auto');
  ga('send', 'pageview');

</script><!-- GitHub Buttons --><script async defer src="https://buttons.github.io/buttons.js"></script><!-- Twitter Widgets --><script>window.twttr = (function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0],
    t = window.twttr || {};
  if (d.getElementById(id)) return t;
  js = d.createElement(s);
  js.id = id;
  js.src = "https://platform.twitter.com/widgets.js";
  fjs.parentNode.insertBefore(js, fjs);

  t._e = [];
  t.ready = function(f) {
    t._e.push(f);
  };

  return t;
}(document, "script", "twitter-wjs"));</script>
</body>
</html>
